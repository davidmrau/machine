{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 951,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 351
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 784,
     "status": "error",
     "timestamp": 1528712348250,
     "user": {
      "displayName": "David Rau",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "113694495446967174103"
     },
     "user_tz": -120
    },
    "id": "KLblPRiyWw77",
    "outputId": "41bc2efc-f235-471a-ed98-cc210816aff6"
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch import nn\n",
    "from seq2seq.util.checkpoint import Checkpoint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from scipy.stats import norm\n",
    "import matplotlib.mlab as mlab\n",
    "import scipy\n",
    "from mpl_toolkits.axes_grid1 import AxesGrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1012,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(object):\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        params = {}\n",
    "        for name, param in self.model.named_parameters():\n",
    "            param = param.data.numpy()\n",
    "            params[name]=pd.DataFrame(param)\n",
    "        self.params = params\n",
    "        \n",
    "    def get_param_names(self):\n",
    "        return [name for name, _ in self.model.named_parameters()]\n",
    "\n",
    "    def get_modules(self):\n",
    "        return [mod for mod in self.model.modules()]\n",
    "\n",
    "    def get_param_by_name(self, name):\n",
    "        return pd.DataFrame(self.params[name])\n",
    "\n",
    "    def heatmap(self):\n",
    "        return {k: sns.heatmap(v) for k, v in self.params.items()}\n",
    "\n",
    "    def apply_mean(self):\n",
    "        return {k: np.ravel(v).mean() if v.shape != (1,1) else np.NaN for k, v in self.params.items()}\n",
    "       \n",
    "    def apply_std(self):\n",
    "        return {k: np.ravel(v).std() if v.shape != (1,1) else np.NaN for k, v in self.params.items()}\n",
    "    \n",
    "    def apply_min(self):\n",
    "        return {k: np.ravel(v).min() for k, v in self.params.items()}\n",
    "    \n",
    "    def apply_max(self):\n",
    "        return {k: np.ravel(v).max() for k, v in self.params.items()}\n",
    "        \n",
    "    def apply_norm(self):\n",
    "        return {k: np.linalg.norm(np.ravel(v)) if v.shape != (1,1) else np.NaN for k, v in self.params.items()}\n",
    "            \n",
    "    def param_to_dist(self,name):\n",
    "        data = self.params[name]\n",
    "        data = np.ravel(data)\n",
    "#         # best fit of data\n",
    "#         (mu, sigma) = norm.fit(data)\n",
    "\n",
    "#         # the histogram of the data\n",
    "#         n, bins, patches = plt.hist(data, 20, normed=1)\n",
    "\n",
    "#         # add a 'best fit' line\n",
    "#         y = mlab.normpdf( bins, mu, sigma)\n",
    "#         l = plt.plot(bins, y, 'r--', linewidth=2)\n",
    "#        return scipy.stats.norm(mu, sigma)\n",
    "        hist, _ = np.histogram(data, bins=50, range=[-1, 1], density=True)\n",
    "        return hist\n",
    "        \n",
    "\n",
    "            \n",
    "class Models(object):\n",
    "    def mean_of(self, data):\n",
    "        one_key = list(data.keys())[0]\n",
    "        return {param: np.mean([data[name][param] for name in data.keys()]) for param in data[one_key].keys()}\n",
    "    \n",
    "    def load_models(self):\n",
    "        models = {}\n",
    "        files = os.listdir(self.model_path)\n",
    "        for file in files: \n",
    "            if not file.startswith('.'):\n",
    "                print('loading: ', self.model_path + '/' + file)\n",
    "                checkpoint = Checkpoint.load(self.model_path + '/' + file)\n",
    "                seq2seq = checkpoint.model\n",
    "                models[file] = Model(seq2seq)\n",
    "        return models\n",
    "    \n",
    "    def __init__(self, model_path,title):\n",
    "        \n",
    "        self.image_folder = 'images/'\n",
    "        self.title = title\n",
    "        self.model_path = model_path\n",
    "        \n",
    "        self.models = self.load_models()\n",
    "\n",
    "        ## calculate mean, std, norm\n",
    "        self.means = {name: model.apply_mean() for name,model in self.models.items()}\n",
    "        self.stds = {name : model.apply_std() for name,model in self.models.items()}\n",
    "        self.norms = {name: model.apply_norm() for name, model in self.models.items()}\n",
    "        self.mins = {name: model.apply_min() for name, model in self.models.items()}\n",
    "        self.maxs = {name: model.apply_max() for name, model in self.models.items()}\n",
    "        \n",
    "        ## caluclate mean of means, stds, norms\n",
    "        self.mean_of_means = self.mean_of(self.means)\n",
    "        self.mean_of_stds = self.mean_of(self.stds)\n",
    "        self.mean_of_norms = self.mean_of(self.norms) \n",
    "        self.maxs = self.mean_of(self.maxs) \n",
    "        self.mins = self.mean_of(self.mins) \n",
    "        \n",
    "        # fill data into df \n",
    "        df = pd.DataFrame.from_dict(self.mean_of_means,  orient='index')\n",
    "        df = df.rename(columns={0: 'mean of means'})\n",
    "        df['mean of stds'] = self.mean_of_stds.values()\n",
    "        df['mean of norms'] = self.mean_of_norms.values()\n",
    "        df['mean of maxs'] = self.maxs.values()\n",
    "        df['mean of mins'] = self.mins.values()\n",
    "        self.df = df        \n",
    "        \n",
    "    \n",
    "    def apply_heatmap(self):\n",
    "        for model_name, model in self.models.items():\n",
    "            for param_name in self.models[model_name].params.keys():\n",
    "                plt.figure()\n",
    "                sns.heatmap(model.params[param_name])\n",
    "                plt.title(self.title + ' (' + model_name + ') - \\n heatmap of param: ' + param_name)\n",
    "                plt.savefig('images/' + self.title + '_' + model_name + '_' + param_name + '.png', dpi=300)\n",
    "                plt.show()\n",
    "                \n",
    "    def apply_heatmap_by_name(self,param_name):\n",
    "        for model_name, model in self.models.items():\n",
    "            plt.figure()\n",
    "            sns.heatmap(model.params[param_name])\n",
    "            plt.title(self.title + ' (' + model_name + ') - \\n heatmap of param: ' + param_name)\n",
    "            plt.savefig(image_folder + self.title + '_' + model_name + '_' + param_name + '.png', dpi=300)\n",
    "            plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1013,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "G02XzQKSWtz9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading:  ../machine-zoo/guided/gru/1\n",
      "loading:  ../machine-zoo/guided/gru/2\n",
      "loading:  ../machine-zoo/guided/gru/3\n",
      "loading:  ../machine-zoo/guided/gru/4\n",
      "loading:  ../machine-zoo/guided/gru/5\n",
      "loading:  ../machine-zoo/baseline/gru/1\n",
      "loading:  ../machine-zoo/baseline/gru/2\n",
      "loading:  ../machine-zoo/baseline/gru/3\n",
      "loading:  ../machine-zoo/baseline/gru/4\n",
      "loading:  ../machine-zoo/baseline/gru/5\n",
      "loading:  ../machine-zoo/guided/lstm/1\n",
      "loading:  ../machine-zoo/guided/lstm/2\n",
      "loading:  ../machine-zoo/guided/lstm/3\n",
      "loading:  ../machine-zoo/guided/lstm/4\n",
      "loading:  ../machine-zoo/guided/lstm/5\n",
      "loading:  ../machine-zoo/baseline/lstm/1\n",
      "loading:  ../machine-zoo/baseline/lstm/2\n",
      "loading:  ../machine-zoo/baseline/lstm/3\n",
      "loading:  ../machine-zoo/baseline/lstm/4\n",
      "loading:  ../machine-zoo/baseline/lstm/5\n"
     ]
    }
   ],
   "source": [
    "guided_gru = Models('../machine-zoo/guided/gru', 'Guided_GRU')\n",
    "baseline_gru = Models('../machine-zoo/baseline/gru', 'Baseline_GRU')\n",
    "\n",
    "guided_lstm = Models('../machine-zoo/guided/lstm', 'Guided_LSTM')\n",
    "baseline_lstm = Models('../machine-zoo/baseline/lstm', 'Baseline_LSTM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sizes of layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1014,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19, 16) encoder.embedding.weight\n",
      "(2048, 16) encoder.rnn.weight_ih_l0\n",
      "(2048, 512) encoder.rnn.weight_hh_l0\n",
      "(2048, 1) encoder.rnn.bias_ih_l0\n",
      "(2048, 1) encoder.rnn.bias_hh_l0\n",
      "(2048, 512) decoder.rnn.weight_ih_l0\n",
      "(2048, 512) decoder.rnn.weight_hh_l0\n",
      "(2048, 1) decoder.rnn.bias_ih_l0\n",
      "(2048, 1) decoder.rnn.bias_hh_l0\n",
      "(11, 512) decoder.embedding.weight\n",
      "(512, 1024) decoder.attention.method.mlp.weight\n",
      "(512, 1) decoder.attention.method.mlp.bias\n",
      "(1, 512) decoder.attention.method.out.weight\n",
      "(1, 1) decoder.attention.method.out.bias\n",
      "(11, 512) decoder.out.weight\n",
      "(11, 1) decoder.out.bias\n",
      "(512, 1024) decoder.ffocus_merge.weight\n",
      "(512, 1) decoder.ffocus_merge.bias\n"
     ]
    }
   ],
   "source": [
    "for name, params in guided_lstm.models['1'].params.items():\n",
    "    print(params.shape, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Analysis\n",
    "\n",
    "Guided GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1015,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean of means</th>\n",
       "      <th>mean of stds</th>\n",
       "      <th>mean of norms</th>\n",
       "      <th>mean of maxs</th>\n",
       "      <th>mean of mins</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>encoder.embedding.weight</th>\n",
       "      <td>-0.000959</td>\n",
       "      <td>0.139349</td>\n",
       "      <td>2.429867</td>\n",
       "      <td>0.376077</td>\n",
       "      <td>-0.403524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>encoder.rnn.weight_ih_l0</th>\n",
       "      <td>-0.000206</td>\n",
       "      <td>0.080538</td>\n",
       "      <td>12.626729</td>\n",
       "      <td>0.542031</td>\n",
       "      <td>-0.511061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>encoder.rnn.weight_hh_l0</th>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.065287</td>\n",
       "      <td>57.897675</td>\n",
       "      <td>0.412640</td>\n",
       "      <td>-0.394051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>encoder.rnn.bias_ih_l0</th>\n",
       "      <td>-0.012083</td>\n",
       "      <td>0.072939</td>\n",
       "      <td>2.898563</td>\n",
       "      <td>0.176322</td>\n",
       "      <td>-0.312060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>encoder.rnn.bias_hh_l0</th>\n",
       "      <td>-0.013354</td>\n",
       "      <td>0.070808</td>\n",
       "      <td>2.824670</td>\n",
       "      <td>0.194362</td>\n",
       "      <td>-0.297983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder.rnn.weight_ih_l0</th>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.065539</td>\n",
       "      <td>58.121387</td>\n",
       "      <td>0.742477</td>\n",
       "      <td>-0.713911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder.rnn.weight_hh_l0</th>\n",
       "      <td>-0.000056</td>\n",
       "      <td>0.058843</td>\n",
       "      <td>52.185558</td>\n",
       "      <td>0.291974</td>\n",
       "      <td>-0.281988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder.rnn.bias_ih_l0</th>\n",
       "      <td>-0.025098</td>\n",
       "      <td>0.059747</td>\n",
       "      <td>2.540183</td>\n",
       "      <td>0.144791</td>\n",
       "      <td>-0.195006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder.rnn.bias_hh_l0</th>\n",
       "      <td>-0.025394</td>\n",
       "      <td>0.059537</td>\n",
       "      <td>2.536941</td>\n",
       "      <td>0.131834</td>\n",
       "      <td>-0.197489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder.embedding.weight</th>\n",
       "      <td>0.000316</td>\n",
       "      <td>0.147676</td>\n",
       "      <td>11.082689</td>\n",
       "      <td>0.395972</td>\n",
       "      <td>-0.391510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder.attention.method.mlp.weight</th>\n",
       "      <td>0.000206</td>\n",
       "      <td>0.067487</td>\n",
       "      <td>48.866028</td>\n",
       "      <td>0.675517</td>\n",
       "      <td>-0.649629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder.attention.method.mlp.bias</th>\n",
       "      <td>0.001523</td>\n",
       "      <td>0.057483</td>\n",
       "      <td>1.303248</td>\n",
       "      <td>0.321878</td>\n",
       "      <td>-0.160765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder.attention.method.out.weight</th>\n",
       "      <td>-0.051289</td>\n",
       "      <td>0.161760</td>\n",
       "      <td>3.844874</td>\n",
       "      <td>0.547918</td>\n",
       "      <td>-1.133493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder.attention.method.out.bias</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3.116120</td>\n",
       "      <td>-3.116120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder.out.weight</th>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.091697</td>\n",
       "      <td>6.883183</td>\n",
       "      <td>0.323680</td>\n",
       "      <td>-0.304038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder.out.bias</th>\n",
       "      <td>-0.008529</td>\n",
       "      <td>0.057211</td>\n",
       "      <td>0.195871</td>\n",
       "      <td>0.076822</td>\n",
       "      <td>-0.117338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder.ffocus_merge.weight</th>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.068721</td>\n",
       "      <td>49.759529</td>\n",
       "      <td>0.605410</td>\n",
       "      <td>-0.602240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder.ffocus_merge.bias</th>\n",
       "      <td>-0.011141</td>\n",
       "      <td>0.061930</td>\n",
       "      <td>1.425724</td>\n",
       "      <td>0.241186</td>\n",
       "      <td>-0.136802</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     mean of means  mean of stds  \\\n",
       "encoder.embedding.weight                 -0.000959      0.139349   \n",
       "encoder.rnn.weight_ih_l0                 -0.000206      0.080538   \n",
       "encoder.rnn.weight_hh_l0                  0.000058      0.065287   \n",
       "encoder.rnn.bias_ih_l0                   -0.012083      0.072939   \n",
       "encoder.rnn.bias_hh_l0                   -0.013354      0.070808   \n",
       "decoder.rnn.weight_ih_l0                  0.000041      0.065539   \n",
       "decoder.rnn.weight_hh_l0                 -0.000056      0.058843   \n",
       "decoder.rnn.bias_ih_l0                   -0.025098      0.059747   \n",
       "decoder.rnn.bias_hh_l0                   -0.025394      0.059537   \n",
       "decoder.embedding.weight                  0.000316      0.147676   \n",
       "decoder.attention.method.mlp.weight       0.000206      0.067487   \n",
       "decoder.attention.method.mlp.bias         0.001523      0.057483   \n",
       "decoder.attention.method.out.weight      -0.051289      0.161760   \n",
       "decoder.attention.method.out.bias              NaN           NaN   \n",
       "decoder.out.weight                        0.000153      0.091697   \n",
       "decoder.out.bias                         -0.008529      0.057211   \n",
       "decoder.ffocus_merge.weight               0.000194      0.068721   \n",
       "decoder.ffocus_merge.bias                -0.011141      0.061930   \n",
       "\n",
       "                                     mean of norms  mean of maxs  mean of mins  \n",
       "encoder.embedding.weight                  2.429867      0.376077     -0.403524  \n",
       "encoder.rnn.weight_ih_l0                 12.626729      0.542031     -0.511061  \n",
       "encoder.rnn.weight_hh_l0                 57.897675      0.412640     -0.394051  \n",
       "encoder.rnn.bias_ih_l0                    2.898563      0.176322     -0.312060  \n",
       "encoder.rnn.bias_hh_l0                    2.824670      0.194362     -0.297983  \n",
       "decoder.rnn.weight_ih_l0                 58.121387      0.742477     -0.713911  \n",
       "decoder.rnn.weight_hh_l0                 52.185558      0.291974     -0.281988  \n",
       "decoder.rnn.bias_ih_l0                    2.540183      0.144791     -0.195006  \n",
       "decoder.rnn.bias_hh_l0                    2.536941      0.131834     -0.197489  \n",
       "decoder.embedding.weight                 11.082689      0.395972     -0.391510  \n",
       "decoder.attention.method.mlp.weight      48.866028      0.675517     -0.649629  \n",
       "decoder.attention.method.mlp.bias         1.303248      0.321878     -0.160765  \n",
       "decoder.attention.method.out.weight       3.844874      0.547918     -1.133493  \n",
       "decoder.attention.method.out.bias              NaN     -3.116120     -3.116120  \n",
       "decoder.out.weight                        6.883183      0.323680     -0.304038  \n",
       "decoder.out.bias                          0.195871      0.076822     -0.117338  \n",
       "decoder.ffocus_merge.weight              49.759529      0.605410     -0.602240  \n",
       "decoder.ffocus_merge.bias                 1.425724      0.241186     -0.136802  "
      ]
     },
     "execution_count": 1015,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "guided_gru.df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1016,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean of means</th>\n",
       "      <th>mean of stds</th>\n",
       "      <th>mean of norms</th>\n",
       "      <th>mean of maxs</th>\n",
       "      <th>mean of mins</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>encoder.embedding.weight</th>\n",
       "      <td>-1.759272e-03</td>\n",
       "      <td>0.146639</td>\n",
       "      <td>2.557299</td>\n",
       "      <td>0.466294</td>\n",
       "      <td>-0.440219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>encoder.rnn.weight_ih_l0</th>\n",
       "      <td>1.795653e-03</td>\n",
       "      <td>0.132039</td>\n",
       "      <td>20.707676</td>\n",
       "      <td>0.657196</td>\n",
       "      <td>-0.636781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>encoder.rnn.weight_hh_l0</th>\n",
       "      <td>2.041644e-04</td>\n",
       "      <td>0.088030</td>\n",
       "      <td>78.066849</td>\n",
       "      <td>0.566109</td>\n",
       "      <td>-0.596124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>encoder.rnn.bias_ih_l0</th>\n",
       "      <td>-1.620729e-02</td>\n",
       "      <td>0.092863</td>\n",
       "      <td>3.695691</td>\n",
       "      <td>0.276811</td>\n",
       "      <td>-0.357539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>encoder.rnn.bias_hh_l0</th>\n",
       "      <td>-1.591059e-02</td>\n",
       "      <td>0.092919</td>\n",
       "      <td>3.696127</td>\n",
       "      <td>0.273887</td>\n",
       "      <td>-0.335439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder.rnn.weight_ih_l0</th>\n",
       "      <td>-1.277724e-04</td>\n",
       "      <td>0.068788</td>\n",
       "      <td>61.002495</td>\n",
       "      <td>0.457143</td>\n",
       "      <td>-0.430959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder.rnn.weight_hh_l0</th>\n",
       "      <td>-1.709472e-04</td>\n",
       "      <td>0.075933</td>\n",
       "      <td>67.339149</td>\n",
       "      <td>0.425063</td>\n",
       "      <td>-0.432390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder.rnn.bias_ih_l0</th>\n",
       "      <td>-2.985862e-02</td>\n",
       "      <td>0.075753</td>\n",
       "      <td>3.191333</td>\n",
       "      <td>0.192314</td>\n",
       "      <td>-0.249801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder.rnn.bias_hh_l0</th>\n",
       "      <td>-2.878932e-02</td>\n",
       "      <td>0.075507</td>\n",
       "      <td>3.167907</td>\n",
       "      <td>0.207104</td>\n",
       "      <td>-0.249486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder.embedding.weight</th>\n",
       "      <td>-6.870941e-05</td>\n",
       "      <td>0.084614</td>\n",
       "      <td>6.350204</td>\n",
       "      <td>0.323575</td>\n",
       "      <td>-0.334121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder.attention.method.mlp.weight</th>\n",
       "      <td>-4.490892e-05</td>\n",
       "      <td>0.072736</td>\n",
       "      <td>52.666878</td>\n",
       "      <td>0.343112</td>\n",
       "      <td>-0.345298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder.attention.method.mlp.bias</th>\n",
       "      <td>-2.278755e-04</td>\n",
       "      <td>0.067650</td>\n",
       "      <td>1.544677</td>\n",
       "      <td>0.177775</td>\n",
       "      <td>-0.187792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder.attention.method.out.weight</th>\n",
       "      <td>-2.773907e-02</td>\n",
       "      <td>0.078564</td>\n",
       "      <td>1.891106</td>\n",
       "      <td>0.192097</td>\n",
       "      <td>-0.258599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder.attention.method.out.bias</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.011534</td>\n",
       "      <td>-0.011534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder.out.weight</th>\n",
       "      <td>-2.991874e-07</td>\n",
       "      <td>0.093911</td>\n",
       "      <td>7.047983</td>\n",
       "      <td>0.374719</td>\n",
       "      <td>-0.368637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder.out.bias</th>\n",
       "      <td>-3.062585e-02</td>\n",
       "      <td>0.070635</td>\n",
       "      <td>0.255743</td>\n",
       "      <td>0.059661</td>\n",
       "      <td>-0.163663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder.ffocus_merge.weight</th>\n",
       "      <td>4.127148e-04</td>\n",
       "      <td>0.065934</td>\n",
       "      <td>47.742027</td>\n",
       "      <td>0.357640</td>\n",
       "      <td>-0.349222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder.ffocus_merge.bias</th>\n",
       "      <td>-4.718875e-02</td>\n",
       "      <td>0.062091</td>\n",
       "      <td>1.765792</td>\n",
       "      <td>0.153604</td>\n",
       "      <td>-0.198715</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     mean of means  mean of stds  \\\n",
       "encoder.embedding.weight             -1.759272e-03      0.146639   \n",
       "encoder.rnn.weight_ih_l0              1.795653e-03      0.132039   \n",
       "encoder.rnn.weight_hh_l0              2.041644e-04      0.088030   \n",
       "encoder.rnn.bias_ih_l0               -1.620729e-02      0.092863   \n",
       "encoder.rnn.bias_hh_l0               -1.591059e-02      0.092919   \n",
       "decoder.rnn.weight_ih_l0             -1.277724e-04      0.068788   \n",
       "decoder.rnn.weight_hh_l0             -1.709472e-04      0.075933   \n",
       "decoder.rnn.bias_ih_l0               -2.985862e-02      0.075753   \n",
       "decoder.rnn.bias_hh_l0               -2.878932e-02      0.075507   \n",
       "decoder.embedding.weight             -6.870941e-05      0.084614   \n",
       "decoder.attention.method.mlp.weight  -4.490892e-05      0.072736   \n",
       "decoder.attention.method.mlp.bias    -2.278755e-04      0.067650   \n",
       "decoder.attention.method.out.weight  -2.773907e-02      0.078564   \n",
       "decoder.attention.method.out.bias              NaN           NaN   \n",
       "decoder.out.weight                   -2.991874e-07      0.093911   \n",
       "decoder.out.bias                     -3.062585e-02      0.070635   \n",
       "decoder.ffocus_merge.weight           4.127148e-04      0.065934   \n",
       "decoder.ffocus_merge.bias            -4.718875e-02      0.062091   \n",
       "\n",
       "                                     mean of norms  mean of maxs  mean of mins  \n",
       "encoder.embedding.weight                  2.557299      0.466294     -0.440219  \n",
       "encoder.rnn.weight_ih_l0                 20.707676      0.657196     -0.636781  \n",
       "encoder.rnn.weight_hh_l0                 78.066849      0.566109     -0.596124  \n",
       "encoder.rnn.bias_ih_l0                    3.695691      0.276811     -0.357539  \n",
       "encoder.rnn.bias_hh_l0                    3.696127      0.273887     -0.335439  \n",
       "decoder.rnn.weight_ih_l0                 61.002495      0.457143     -0.430959  \n",
       "decoder.rnn.weight_hh_l0                 67.339149      0.425063     -0.432390  \n",
       "decoder.rnn.bias_ih_l0                    3.191333      0.192314     -0.249801  \n",
       "decoder.rnn.bias_hh_l0                    3.167907      0.207104     -0.249486  \n",
       "decoder.embedding.weight                  6.350204      0.323575     -0.334121  \n",
       "decoder.attention.method.mlp.weight      52.666878      0.343112     -0.345298  \n",
       "decoder.attention.method.mlp.bias         1.544677      0.177775     -0.187792  \n",
       "decoder.attention.method.out.weight       1.891106      0.192097     -0.258599  \n",
       "decoder.attention.method.out.bias              NaN     -0.011534     -0.011534  \n",
       "decoder.out.weight                        7.047983      0.374719     -0.368637  \n",
       "decoder.out.bias                          0.255743      0.059661     -0.163663  \n",
       "decoder.ffocus_merge.weight              47.742027      0.357640     -0.349222  \n",
       "decoder.ffocus_merge.bias                 1.765792      0.153604     -0.198715  "
      ]
     },
     "execution_count": 1016,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_gru.df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guided LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1017,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean of means</th>\n",
       "      <th>mean of stds</th>\n",
       "      <th>mean of norms</th>\n",
       "      <th>mean of maxs</th>\n",
       "      <th>mean of mins</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>encoder.embedding.weight</th>\n",
       "      <td>0.002058</td>\n",
       "      <td>0.179018</td>\n",
       "      <td>3.123551</td>\n",
       "      <td>0.543385</td>\n",
       "      <td>-0.524266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>encoder.rnn.weight_ih_l0</th>\n",
       "      <td>0.000245</td>\n",
       "      <td>0.113211</td>\n",
       "      <td>20.516216</td>\n",
       "      <td>0.710162</td>\n",
       "      <td>-0.710747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>encoder.rnn.weight_hh_l0</th>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.071164</td>\n",
       "      <td>72.872803</td>\n",
       "      <td>0.551239</td>\n",
       "      <td>-0.668254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>encoder.rnn.bias_ih_l0</th>\n",
       "      <td>-0.010346</td>\n",
       "      <td>0.082105</td>\n",
       "      <td>3.746127</td>\n",
       "      <td>0.408405</td>\n",
       "      <td>-0.251434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>encoder.rnn.bias_hh_l0</th>\n",
       "      <td>-0.010515</td>\n",
       "      <td>0.081048</td>\n",
       "      <td>3.700511</td>\n",
       "      <td>0.403438</td>\n",
       "      <td>-0.238568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder.rnn.weight_ih_l0</th>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.080769</td>\n",
       "      <td>82.708237</td>\n",
       "      <td>0.941351</td>\n",
       "      <td>-0.865073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder.rnn.weight_hh_l0</th>\n",
       "      <td>-0.000130</td>\n",
       "      <td>0.073191</td>\n",
       "      <td>74.948914</td>\n",
       "      <td>0.402468</td>\n",
       "      <td>-0.391413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder.rnn.bias_ih_l0</th>\n",
       "      <td>-0.024615</td>\n",
       "      <td>0.059836</td>\n",
       "      <td>2.930603</td>\n",
       "      <td>0.152430</td>\n",
       "      <td>-0.214242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder.rnn.bias_hh_l0</th>\n",
       "      <td>-0.024132</td>\n",
       "      <td>0.060696</td>\n",
       "      <td>2.957357</td>\n",
       "      <td>0.167402</td>\n",
       "      <td>-0.216230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder.embedding.weight</th>\n",
       "      <td>0.000231</td>\n",
       "      <td>0.179740</td>\n",
       "      <td>13.489433</td>\n",
       "      <td>0.491869</td>\n",
       "      <td>-0.492699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder.attention.method.mlp.weight</th>\n",
       "      <td>-0.000051</td>\n",
       "      <td>0.072047</td>\n",
       "      <td>52.168163</td>\n",
       "      <td>0.675322</td>\n",
       "      <td>-0.655570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder.attention.method.mlp.bias</th>\n",
       "      <td>-0.004275</td>\n",
       "      <td>0.059068</td>\n",
       "      <td>1.344930</td>\n",
       "      <td>0.149346</td>\n",
       "      <td>-0.203927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder.attention.method.out.weight</th>\n",
       "      <td>-0.021032</td>\n",
       "      <td>0.150352</td>\n",
       "      <td>3.439049</td>\n",
       "      <td>0.644234</td>\n",
       "      <td>-0.763243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder.attention.method.out.bias</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.256781</td>\n",
       "      <td>-2.256781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder.out.weight</th>\n",
       "      <td>-0.000893</td>\n",
       "      <td>0.140305</td>\n",
       "      <td>10.529896</td>\n",
       "      <td>0.636434</td>\n",
       "      <td>-0.688260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder.out.bias</th>\n",
       "      <td>-0.019884</td>\n",
       "      <td>0.064462</td>\n",
       "      <td>0.225579</td>\n",
       "      <td>0.073007</td>\n",
       "      <td>-0.135263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder.ffocus_merge.weight</th>\n",
       "      <td>0.000581</td>\n",
       "      <td>0.097283</td>\n",
       "      <td>70.442200</td>\n",
       "      <td>0.940061</td>\n",
       "      <td>-1.018749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder.ffocus_merge.bias</th>\n",
       "      <td>0.001793</td>\n",
       "      <td>0.091905</td>\n",
       "      <td>2.081349</td>\n",
       "      <td>0.518395</td>\n",
       "      <td>-0.174709</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     mean of means  mean of stds  \\\n",
       "encoder.embedding.weight                  0.002058      0.179018   \n",
       "encoder.rnn.weight_ih_l0                  0.000245      0.113211   \n",
       "encoder.rnn.weight_hh_l0                  0.000026      0.071164   \n",
       "encoder.rnn.bias_ih_l0                   -0.010346      0.082105   \n",
       "encoder.rnn.bias_hh_l0                   -0.010515      0.081048   \n",
       "decoder.rnn.weight_ih_l0                  0.000095      0.080769   \n",
       "decoder.rnn.weight_hh_l0                 -0.000130      0.073191   \n",
       "decoder.rnn.bias_ih_l0                   -0.024615      0.059836   \n",
       "decoder.rnn.bias_hh_l0                   -0.024132      0.060696   \n",
       "decoder.embedding.weight                  0.000231      0.179740   \n",
       "decoder.attention.method.mlp.weight      -0.000051      0.072047   \n",
       "decoder.attention.method.mlp.bias        -0.004275      0.059068   \n",
       "decoder.attention.method.out.weight      -0.021032      0.150352   \n",
       "decoder.attention.method.out.bias              NaN           NaN   \n",
       "decoder.out.weight                       -0.000893      0.140305   \n",
       "decoder.out.bias                         -0.019884      0.064462   \n",
       "decoder.ffocus_merge.weight               0.000581      0.097283   \n",
       "decoder.ffocus_merge.bias                 0.001793      0.091905   \n",
       "\n",
       "                                     mean of norms  mean of maxs  mean of mins  \n",
       "encoder.embedding.weight                  3.123551      0.543385     -0.524266  \n",
       "encoder.rnn.weight_ih_l0                 20.516216      0.710162     -0.710747  \n",
       "encoder.rnn.weight_hh_l0                 72.872803      0.551239     -0.668254  \n",
       "encoder.rnn.bias_ih_l0                    3.746127      0.408405     -0.251434  \n",
       "encoder.rnn.bias_hh_l0                    3.700511      0.403438     -0.238568  \n",
       "decoder.rnn.weight_ih_l0                 82.708237      0.941351     -0.865073  \n",
       "decoder.rnn.weight_hh_l0                 74.948914      0.402468     -0.391413  \n",
       "decoder.rnn.bias_ih_l0                    2.930603      0.152430     -0.214242  \n",
       "decoder.rnn.bias_hh_l0                    2.957357      0.167402     -0.216230  \n",
       "decoder.embedding.weight                 13.489433      0.491869     -0.492699  \n",
       "decoder.attention.method.mlp.weight      52.168163      0.675322     -0.655570  \n",
       "decoder.attention.method.mlp.bias         1.344930      0.149346     -0.203927  \n",
       "decoder.attention.method.out.weight       3.439049      0.644234     -0.763243  \n",
       "decoder.attention.method.out.bias              NaN     -2.256781     -2.256781  \n",
       "decoder.out.weight                       10.529896      0.636434     -0.688260  \n",
       "decoder.out.bias                          0.225579      0.073007     -0.135263  \n",
       "decoder.ffocus_merge.weight              70.442200      0.940061     -1.018749  \n",
       "decoder.ffocus_merge.bias                 2.081349      0.518395     -0.174709  "
      ]
     },
     "execution_count": 1017,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "guided_lstm.df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1018,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean of means</th>\n",
       "      <th>mean of stds</th>\n",
       "      <th>mean of norms</th>\n",
       "      <th>mean of maxs</th>\n",
       "      <th>mean of mins</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>encoder.embedding.weight</th>\n",
       "      <td>-0.001442</td>\n",
       "      <td>0.162086</td>\n",
       "      <td>2.826329</td>\n",
       "      <td>0.492238</td>\n",
       "      <td>-0.502056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>encoder.rnn.weight_ih_l0</th>\n",
       "      <td>0.000913</td>\n",
       "      <td>0.146842</td>\n",
       "      <td>26.588650</td>\n",
       "      <td>0.684907</td>\n",
       "      <td>-0.707094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>encoder.rnn.weight_hh_l0</th>\n",
       "      <td>-0.000176</td>\n",
       "      <td>0.089515</td>\n",
       "      <td>91.664444</td>\n",
       "      <td>0.570511</td>\n",
       "      <td>-0.610069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>encoder.rnn.bias_ih_l0</th>\n",
       "      <td>-0.037526</td>\n",
       "      <td>0.090355</td>\n",
       "      <td>4.483636</td>\n",
       "      <td>0.339953</td>\n",
       "      <td>-0.328324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>encoder.rnn.bias_hh_l0</th>\n",
       "      <td>-0.038465</td>\n",
       "      <td>0.090417</td>\n",
       "      <td>4.501397</td>\n",
       "      <td>0.307354</td>\n",
       "      <td>-0.318395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder.rnn.weight_ih_l0</th>\n",
       "      <td>-0.000139</td>\n",
       "      <td>0.080955</td>\n",
       "      <td>82.899498</td>\n",
       "      <td>0.517021</td>\n",
       "      <td>-0.515518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder.rnn.weight_hh_l0</th>\n",
       "      <td>-0.000294</td>\n",
       "      <td>0.084335</td>\n",
       "      <td>86.370056</td>\n",
       "      <td>0.489893</td>\n",
       "      <td>-0.495761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder.rnn.bias_ih_l0</th>\n",
       "      <td>-0.035166</td>\n",
       "      <td>0.065420</td>\n",
       "      <td>3.369680</td>\n",
       "      <td>0.178394</td>\n",
       "      <td>-0.243665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder.rnn.bias_hh_l0</th>\n",
       "      <td>-0.033474</td>\n",
       "      <td>0.065755</td>\n",
       "      <td>3.347765</td>\n",
       "      <td>0.171613</td>\n",
       "      <td>-0.239341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder.embedding.weight</th>\n",
       "      <td>-0.000122</td>\n",
       "      <td>0.132717</td>\n",
       "      <td>9.960362</td>\n",
       "      <td>0.474859</td>\n",
       "      <td>-0.472432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder.attention.method.mlp.weight</th>\n",
       "      <td>0.000151</td>\n",
       "      <td>0.076478</td>\n",
       "      <td>55.376179</td>\n",
       "      <td>0.431372</td>\n",
       "      <td>-0.409194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder.attention.method.mlp.bias</th>\n",
       "      <td>-0.001529</td>\n",
       "      <td>0.076091</td>\n",
       "      <td>1.727324</td>\n",
       "      <td>0.204895</td>\n",
       "      <td>-0.233515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder.attention.method.out.weight</th>\n",
       "      <td>-0.016361</td>\n",
       "      <td>0.074538</td>\n",
       "      <td>1.732655</td>\n",
       "      <td>0.212136</td>\n",
       "      <td>-0.234652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder.attention.method.out.bias</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.013143</td>\n",
       "      <td>-0.013143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder.out.weight</th>\n",
       "      <td>-0.000683</td>\n",
       "      <td>0.132103</td>\n",
       "      <td>9.916939</td>\n",
       "      <td>0.657928</td>\n",
       "      <td>-0.652494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder.out.bias</th>\n",
       "      <td>-0.052845</td>\n",
       "      <td>0.090152</td>\n",
       "      <td>0.349216</td>\n",
       "      <td>0.055984</td>\n",
       "      <td>-0.216444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder.ffocus_merge.weight</th>\n",
       "      <td>-0.000076</td>\n",
       "      <td>0.081449</td>\n",
       "      <td>58.976460</td>\n",
       "      <td>0.427680</td>\n",
       "      <td>-0.436542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder.ffocus_merge.bias</th>\n",
       "      <td>-0.026911</td>\n",
       "      <td>0.073290</td>\n",
       "      <td>1.773785</td>\n",
       "      <td>0.202077</td>\n",
       "      <td>-0.213816</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     mean of means  mean of stds  \\\n",
       "encoder.embedding.weight                 -0.001442      0.162086   \n",
       "encoder.rnn.weight_ih_l0                  0.000913      0.146842   \n",
       "encoder.rnn.weight_hh_l0                 -0.000176      0.089515   \n",
       "encoder.rnn.bias_ih_l0                   -0.037526      0.090355   \n",
       "encoder.rnn.bias_hh_l0                   -0.038465      0.090417   \n",
       "decoder.rnn.weight_ih_l0                 -0.000139      0.080955   \n",
       "decoder.rnn.weight_hh_l0                 -0.000294      0.084335   \n",
       "decoder.rnn.bias_ih_l0                   -0.035166      0.065420   \n",
       "decoder.rnn.bias_hh_l0                   -0.033474      0.065755   \n",
       "decoder.embedding.weight                 -0.000122      0.132717   \n",
       "decoder.attention.method.mlp.weight       0.000151      0.076478   \n",
       "decoder.attention.method.mlp.bias        -0.001529      0.076091   \n",
       "decoder.attention.method.out.weight      -0.016361      0.074538   \n",
       "decoder.attention.method.out.bias              NaN           NaN   \n",
       "decoder.out.weight                       -0.000683      0.132103   \n",
       "decoder.out.bias                         -0.052845      0.090152   \n",
       "decoder.ffocus_merge.weight              -0.000076      0.081449   \n",
       "decoder.ffocus_merge.bias                -0.026911      0.073290   \n",
       "\n",
       "                                     mean of norms  mean of maxs  mean of mins  \n",
       "encoder.embedding.weight                  2.826329      0.492238     -0.502056  \n",
       "encoder.rnn.weight_ih_l0                 26.588650      0.684907     -0.707094  \n",
       "encoder.rnn.weight_hh_l0                 91.664444      0.570511     -0.610069  \n",
       "encoder.rnn.bias_ih_l0                    4.483636      0.339953     -0.328324  \n",
       "encoder.rnn.bias_hh_l0                    4.501397      0.307354     -0.318395  \n",
       "decoder.rnn.weight_ih_l0                 82.899498      0.517021     -0.515518  \n",
       "decoder.rnn.weight_hh_l0                 86.370056      0.489893     -0.495761  \n",
       "decoder.rnn.bias_ih_l0                    3.369680      0.178394     -0.243665  \n",
       "decoder.rnn.bias_hh_l0                    3.347765      0.171613     -0.239341  \n",
       "decoder.embedding.weight                  9.960362      0.474859     -0.472432  \n",
       "decoder.attention.method.mlp.weight      55.376179      0.431372     -0.409194  \n",
       "decoder.attention.method.mlp.bias         1.727324      0.204895     -0.233515  \n",
       "decoder.attention.method.out.weight       1.732655      0.212136     -0.234652  \n",
       "decoder.attention.method.out.bias              NaN     -0.013143     -0.013143  \n",
       "decoder.out.weight                        9.916939      0.657928     -0.652494  \n",
       "decoder.out.bias                          0.349216      0.055984     -0.216444  \n",
       "decoder.ffocus_merge.weight              58.976460      0.427680     -0.436542  \n",
       "decoder.ffocus_merge.bias                 1.773785      0.202077     -0.213816  "
      ]
     },
     "execution_count": 1018,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_lstm.df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of Distribution\n",
    "\n",
    "GRU Guided vs. Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1004,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Analysis(object):\n",
    "    \n",
    "    def return_intersection(self, hist_1, hist_2):\n",
    "        minima = np.minimum(hist_1, hist_2)\n",
    "        intersection = np.true_divide(np.sum(minima), np.sum(hist_2))\n",
    "        return intersection\n",
    "\n",
    "    def KL(self,dist_1, dist_2):\n",
    "        x = np.linspace(-1, 1, 100)\n",
    "        return scipy.stats.entropy(dist_1.pdf(x),dist_2.pdf(x))  \n",
    "    \n",
    "    def apply_dist(self):\n",
    "        dist = {}\n",
    "        for model_name_A in self.models_A.keys():\n",
    "            for model_name_B in self.models_B.keys():\n",
    "                per_model = {}\n",
    "                for param in self.models_A[list(self.models_A.keys())[0]].params.keys():\n",
    "                    if not self.models_A[model_name_A].params[param].shape == (1,1):\n",
    "                        dist_1 = self.models_A[model_name_A].param_to_dist(param)\n",
    "                        dist_2 = self.models_B[model_name_B].param_to_dist(param)\n",
    "                        per_model[param] = self.return_intersection(dist_1, dist_2)\n",
    "                key = model_name_A + '_' + model_name_B\n",
    "                dist[key] = per_model\n",
    "        return pd.DataFrame.from_dict(dist, orient='index')\n",
    "    \n",
    "    def __init__(self, models_A, models_B):\n",
    "        self.models_A = models_A.models\n",
    "        self.models_B = models_B.models\n",
    "        self.dist = self.apply_dist()\n",
    "        \n",
    "    def apply_dist_by_name(self,param):\n",
    "        for model_name in self.models_A.keys():\n",
    "            assert(self.models_A[model_name].params[param].shape != (1,1))\n",
    "            dist_1 = self.models_A[model_name].param_to_dist(param)\n",
    "            dist_2 = self.models_B[model_name].param_to_dist(param)\n",
    "            print(self.return_intersection(dist_1, dist_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1005,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "analysis_GRU = Analysis(baseline_gru, guided_gru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1007,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encoder.embedding.weight</th>\n",
       "      <th>encoder.rnn.weight_ih_l0</th>\n",
       "      <th>encoder.rnn.weight_hh_l0</th>\n",
       "      <th>encoder.rnn.bias_ih_l0</th>\n",
       "      <th>encoder.rnn.bias_hh_l0</th>\n",
       "      <th>decoder.rnn.weight_ih_l0</th>\n",
       "      <th>decoder.rnn.weight_hh_l0</th>\n",
       "      <th>decoder.rnn.bias_ih_l0</th>\n",
       "      <th>decoder.rnn.bias_hh_l0</th>\n",
       "      <th>decoder.embedding.weight</th>\n",
       "      <th>decoder.attention.method.mlp.weight</th>\n",
       "      <th>decoder.attention.method.mlp.bias</th>\n",
       "      <th>decoder.attention.method.out.weight</th>\n",
       "      <th>decoder.out.weight</th>\n",
       "      <th>decoder.out.bias</th>\n",
       "      <th>decoder.ffocus_merge.weight</th>\n",
       "      <th>decoder.ffocus_merge.bias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.868816</td>\n",
       "      <td>0.744264</td>\n",
       "      <td>0.864755</td>\n",
       "      <td>0.875599</td>\n",
       "      <td>0.872526</td>\n",
       "      <td>0.933552</td>\n",
       "      <td>0.892613</td>\n",
       "      <td>0.893203</td>\n",
       "      <td>0.893776</td>\n",
       "      <td>0.566214</td>\n",
       "      <td>0.941055</td>\n",
       "      <td>0.874766</td>\n",
       "      <td>0.565773</td>\n",
       "      <td>0.918111</td>\n",
       "      <td>0.592727</td>\n",
       "      <td>0.956731</td>\n",
       "      <td>0.786563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.016620</td>\n",
       "      <td>0.019523</td>\n",
       "      <td>0.019201</td>\n",
       "      <td>0.031462</td>\n",
       "      <td>0.034271</td>\n",
       "      <td>0.012509</td>\n",
       "      <td>0.015916</td>\n",
       "      <td>0.016076</td>\n",
       "      <td>0.022599</td>\n",
       "      <td>0.032272</td>\n",
       "      <td>0.017775</td>\n",
       "      <td>0.024357</td>\n",
       "      <td>0.116134</td>\n",
       "      <td>0.015593</td>\n",
       "      <td>0.141616</td>\n",
       "      <td>0.011778</td>\n",
       "      <td>0.034763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.845395</td>\n",
       "      <td>0.703044</td>\n",
       "      <td>0.826725</td>\n",
       "      <td>0.827474</td>\n",
       "      <td>0.830078</td>\n",
       "      <td>0.912841</td>\n",
       "      <td>0.861463</td>\n",
       "      <td>0.867839</td>\n",
       "      <td>0.848307</td>\n",
       "      <td>0.517578</td>\n",
       "      <td>0.910160</td>\n",
       "      <td>0.824219</td>\n",
       "      <td>0.365234</td>\n",
       "      <td>0.891335</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.936085</td>\n",
       "      <td>0.730469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.858553</td>\n",
       "      <td>0.732178</td>\n",
       "      <td>0.854861</td>\n",
       "      <td>0.847005</td>\n",
       "      <td>0.847656</td>\n",
       "      <td>0.923400</td>\n",
       "      <td>0.880046</td>\n",
       "      <td>0.882812</td>\n",
       "      <td>0.878255</td>\n",
       "      <td>0.540661</td>\n",
       "      <td>0.933981</td>\n",
       "      <td>0.859375</td>\n",
       "      <td>0.474609</td>\n",
       "      <td>0.908913</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.947453</td>\n",
       "      <td>0.765625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.865132</td>\n",
       "      <td>0.744303</td>\n",
       "      <td>0.865724</td>\n",
       "      <td>0.881510</td>\n",
       "      <td>0.863281</td>\n",
       "      <td>0.931273</td>\n",
       "      <td>0.892869</td>\n",
       "      <td>0.891927</td>\n",
       "      <td>0.893229</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.938148</td>\n",
       "      <td>0.876953</td>\n",
       "      <td>0.582031</td>\n",
       "      <td>0.919212</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.955082</td>\n",
       "      <td>0.777344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.881579</td>\n",
       "      <td>0.757406</td>\n",
       "      <td>0.875916</td>\n",
       "      <td>0.890625</td>\n",
       "      <td>0.882161</td>\n",
       "      <td>0.945811</td>\n",
       "      <td>0.905159</td>\n",
       "      <td>0.902995</td>\n",
       "      <td>0.910156</td>\n",
       "      <td>0.586470</td>\n",
       "      <td>0.948311</td>\n",
       "      <td>0.888672</td>\n",
       "      <td>0.651218</td>\n",
       "      <td>0.930220</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.967932</td>\n",
       "      <td>0.818359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.904605</td>\n",
       "      <td>0.776123</td>\n",
       "      <td>0.903155</td>\n",
       "      <td>0.927734</td>\n",
       "      <td>0.940104</td>\n",
       "      <td>0.953189</td>\n",
       "      <td>0.923272</td>\n",
       "      <td>0.929036</td>\n",
       "      <td>0.934245</td>\n",
       "      <td>0.640270</td>\n",
       "      <td>0.974909</td>\n",
       "      <td>0.919922</td>\n",
       "      <td>0.757813</td>\n",
       "      <td>0.945845</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.973284</td>\n",
       "      <td>0.861328</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       encoder.embedding.weight  encoder.rnn.weight_ih_l0  \\\n",
       "count                 25.000000                 25.000000   \n",
       "mean                   0.868816                  0.744264   \n",
       "std                    0.016620                  0.019523   \n",
       "min                    0.845395                  0.703044   \n",
       "25%                    0.858553                  0.732178   \n",
       "50%                    0.865132                  0.744303   \n",
       "75%                    0.881579                  0.757406   \n",
       "max                    0.904605                  0.776123   \n",
       "\n",
       "       encoder.rnn.weight_hh_l0  encoder.rnn.bias_ih_l0  \\\n",
       "count                 25.000000               25.000000   \n",
       "mean                   0.864755                0.875599   \n",
       "std                    0.019201                0.031462   \n",
       "min                    0.826725                0.827474   \n",
       "25%                    0.854861                0.847005   \n",
       "50%                    0.865724                0.881510   \n",
       "75%                    0.875916                0.890625   \n",
       "max                    0.903155                0.927734   \n",
       "\n",
       "       encoder.rnn.bias_hh_l0  decoder.rnn.weight_ih_l0  \\\n",
       "count               25.000000                 25.000000   \n",
       "mean                 0.872526                  0.933552   \n",
       "std                  0.034271                  0.012509   \n",
       "min                  0.830078                  0.912841   \n",
       "25%                  0.847656                  0.923400   \n",
       "50%                  0.863281                  0.931273   \n",
       "75%                  0.882161                  0.945811   \n",
       "max                  0.940104                  0.953189   \n",
       "\n",
       "       decoder.rnn.weight_hh_l0  decoder.rnn.bias_ih_l0  \\\n",
       "count                 25.000000               25.000000   \n",
       "mean                   0.892613                0.893203   \n",
       "std                    0.015916                0.016076   \n",
       "min                    0.861463                0.867839   \n",
       "25%                    0.880046                0.882812   \n",
       "50%                    0.892869                0.891927   \n",
       "75%                    0.905159                0.902995   \n",
       "max                    0.923272                0.929036   \n",
       "\n",
       "       decoder.rnn.bias_hh_l0  decoder.embedding.weight  \\\n",
       "count               25.000000                 25.000000   \n",
       "mean                 0.893776                  0.566214   \n",
       "std                  0.022599                  0.032272   \n",
       "min                  0.848307                  0.517578   \n",
       "25%                  0.878255                  0.540661   \n",
       "50%                  0.893229                  0.562500   \n",
       "75%                  0.910156                  0.586470   \n",
       "max                  0.934245                  0.640270   \n",
       "\n",
       "       decoder.attention.method.mlp.weight  decoder.attention.method.mlp.bias  \\\n",
       "count                            25.000000                          25.000000   \n",
       "mean                              0.941055                           0.874766   \n",
       "std                               0.017775                           0.024357   \n",
       "min                               0.910160                           0.824219   \n",
       "25%                               0.933981                           0.859375   \n",
       "50%                               0.938148                           0.876953   \n",
       "75%                               0.948311                           0.888672   \n",
       "max                               0.974909                           0.919922   \n",
       "\n",
       "       decoder.attention.method.out.weight  decoder.out.weight  \\\n",
       "count                            25.000000           25.000000   \n",
       "mean                              0.565773            0.918111   \n",
       "std                               0.116134            0.015593   \n",
       "min                               0.365234            0.891335   \n",
       "25%                               0.474609            0.908913   \n",
       "50%                               0.582031            0.919212   \n",
       "75%                               0.651218            0.930220   \n",
       "max                               0.757813            0.945845   \n",
       "\n",
       "       decoder.out.bias  decoder.ffocus_merge.weight  \\\n",
       "count         25.000000                    25.000000   \n",
       "mean           0.592727                     0.956731   \n",
       "std            0.141616                     0.011778   \n",
       "min            0.363636                     0.936085   \n",
       "25%            0.454545                     0.947453   \n",
       "50%            0.545455                     0.955082   \n",
       "75%            0.727273                     0.967932   \n",
       "max            0.818182                     0.973284   \n",
       "\n",
       "       decoder.ffocus_merge.bias  \n",
       "count                  25.000000  \n",
       "mean                    0.786563  \n",
       "std                     0.034763  \n",
       "min                     0.730469  \n",
       "25%                     0.765625  \n",
       "50%                     0.777344  \n",
       "75%                     0.818359  \n",
       "max                     0.861328  "
      ]
     },
     "execution_count": 1007,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis_GRU.dist.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM Guided vs. Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1008,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "analysis_LSTM = Analysis(guided_lstm, baseline_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1009,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encoder.embedding.weight</th>\n",
       "      <th>encoder.rnn.weight_ih_l0</th>\n",
       "      <th>encoder.rnn.weight_hh_l0</th>\n",
       "      <th>encoder.rnn.bias_ih_l0</th>\n",
       "      <th>encoder.rnn.bias_hh_l0</th>\n",
       "      <th>decoder.rnn.weight_ih_l0</th>\n",
       "      <th>decoder.rnn.weight_hh_l0</th>\n",
       "      <th>decoder.rnn.bias_ih_l0</th>\n",
       "      <th>decoder.rnn.bias_hh_l0</th>\n",
       "      <th>decoder.embedding.weight</th>\n",
       "      <th>decoder.attention.method.mlp.weight</th>\n",
       "      <th>decoder.attention.method.mlp.bias</th>\n",
       "      <th>decoder.attention.method.out.weight</th>\n",
       "      <th>decoder.out.weight</th>\n",
       "      <th>decoder.out.bias</th>\n",
       "      <th>decoder.ffocus_merge.weight</th>\n",
       "      <th>decoder.ffocus_merge.bias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.844079</td>\n",
       "      <td>0.844094</td>\n",
       "      <td>0.898595</td>\n",
       "      <td>0.874434</td>\n",
       "      <td>0.868320</td>\n",
       "      <td>0.951818</td>\n",
       "      <td>0.938035</td>\n",
       "      <td>0.910605</td>\n",
       "      <td>0.917969</td>\n",
       "      <td>0.661364</td>\n",
       "      <td>0.942557</td>\n",
       "      <td>0.845234</td>\n",
       "      <td>0.636315</td>\n",
       "      <td>0.887791</td>\n",
       "      <td>0.549091</td>\n",
       "      <td>0.945640</td>\n",
       "      <td>0.860391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.028249</td>\n",
       "      <td>0.090856</td>\n",
       "      <td>0.064630</td>\n",
       "      <td>0.092074</td>\n",
       "      <td>0.096388</td>\n",
       "      <td>0.037297</td>\n",
       "      <td>0.052990</td>\n",
       "      <td>0.028361</td>\n",
       "      <td>0.029646</td>\n",
       "      <td>0.078769</td>\n",
       "      <td>0.053289</td>\n",
       "      <td>0.042907</td>\n",
       "      <td>0.132852</td>\n",
       "      <td>0.033851</td>\n",
       "      <td>0.124427</td>\n",
       "      <td>0.019945</td>\n",
       "      <td>0.036527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.782895</td>\n",
       "      <td>0.652130</td>\n",
       "      <td>0.776758</td>\n",
       "      <td>0.683105</td>\n",
       "      <td>0.677246</td>\n",
       "      <td>0.869842</td>\n",
       "      <td>0.824250</td>\n",
       "      <td>0.864746</td>\n",
       "      <td>0.854980</td>\n",
       "      <td>0.526456</td>\n",
       "      <td>0.830433</td>\n",
       "      <td>0.755859</td>\n",
       "      <td>0.386719</td>\n",
       "      <td>0.832564</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.900955</td>\n",
       "      <td>0.787109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.822368</td>\n",
       "      <td>0.768921</td>\n",
       "      <td>0.862494</td>\n",
       "      <td>0.857910</td>\n",
       "      <td>0.841797</td>\n",
       "      <td>0.935133</td>\n",
       "      <td>0.936102</td>\n",
       "      <td>0.889648</td>\n",
       "      <td>0.891602</td>\n",
       "      <td>0.608132</td>\n",
       "      <td>0.918846</td>\n",
       "      <td>0.822266</td>\n",
       "      <td>0.590539</td>\n",
       "      <td>0.863814</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.935379</td>\n",
       "      <td>0.833984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.851974</td>\n",
       "      <td>0.858276</td>\n",
       "      <td>0.906240</td>\n",
       "      <td>0.910156</td>\n",
       "      <td>0.905762</td>\n",
       "      <td>0.969708</td>\n",
       "      <td>0.953884</td>\n",
       "      <td>0.913086</td>\n",
       "      <td>0.929199</td>\n",
       "      <td>0.655540</td>\n",
       "      <td>0.969986</td>\n",
       "      <td>0.851562</td>\n",
       "      <td>0.649133</td>\n",
       "      <td>0.881570</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.947441</td>\n",
       "      <td>0.869141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.868421</td>\n",
       "      <td>0.913635</td>\n",
       "      <td>0.938403</td>\n",
       "      <td>0.935547</td>\n",
       "      <td>0.943359</td>\n",
       "      <td>0.977510</td>\n",
       "      <td>0.976146</td>\n",
       "      <td>0.927734</td>\n",
       "      <td>0.937012</td>\n",
       "      <td>0.702770</td>\n",
       "      <td>0.983482</td>\n",
       "      <td>0.880859</td>\n",
       "      <td>0.744301</td>\n",
       "      <td>0.911932</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.963771</td>\n",
       "      <td>0.880859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.878289</td>\n",
       "      <td>0.968445</td>\n",
       "      <td>0.995316</td>\n",
       "      <td>0.966309</td>\n",
       "      <td>0.965820</td>\n",
       "      <td>0.991642</td>\n",
       "      <td>0.995377</td>\n",
       "      <td>0.957520</td>\n",
       "      <td>0.961914</td>\n",
       "      <td>0.815341</td>\n",
       "      <td>0.991564</td>\n",
       "      <td>0.902344</td>\n",
       "      <td>0.822266</td>\n",
       "      <td>0.956143</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.971615</td>\n",
       "      <td>0.923828</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       encoder.embedding.weight  encoder.rnn.weight_ih_l0  \\\n",
       "count                 25.000000                 25.000000   \n",
       "mean                   0.844079                  0.844094   \n",
       "std                    0.028249                  0.090856   \n",
       "min                    0.782895                  0.652130   \n",
       "25%                    0.822368                  0.768921   \n",
       "50%                    0.851974                  0.858276   \n",
       "75%                    0.868421                  0.913635   \n",
       "max                    0.878289                  0.968445   \n",
       "\n",
       "       encoder.rnn.weight_hh_l0  encoder.rnn.bias_ih_l0  \\\n",
       "count                 25.000000               25.000000   \n",
       "mean                   0.898595                0.874434   \n",
       "std                    0.064630                0.092074   \n",
       "min                    0.776758                0.683105   \n",
       "25%                    0.862494                0.857910   \n",
       "50%                    0.906240                0.910156   \n",
       "75%                    0.938403                0.935547   \n",
       "max                    0.995316                0.966309   \n",
       "\n",
       "       encoder.rnn.bias_hh_l0  decoder.rnn.weight_ih_l0  \\\n",
       "count               25.000000                 25.000000   \n",
       "mean                 0.868320                  0.951818   \n",
       "std                  0.096388                  0.037297   \n",
       "min                  0.677246                  0.869842   \n",
       "25%                  0.841797                  0.935133   \n",
       "50%                  0.905762                  0.969708   \n",
       "75%                  0.943359                  0.977510   \n",
       "max                  0.965820                  0.991642   \n",
       "\n",
       "       decoder.rnn.weight_hh_l0  decoder.rnn.bias_ih_l0  \\\n",
       "count                 25.000000               25.000000   \n",
       "mean                   0.938035                0.910605   \n",
       "std                    0.052990                0.028361   \n",
       "min                    0.824250                0.864746   \n",
       "25%                    0.936102                0.889648   \n",
       "50%                    0.953884                0.913086   \n",
       "75%                    0.976146                0.927734   \n",
       "max                    0.995377                0.957520   \n",
       "\n",
       "       decoder.rnn.bias_hh_l0  decoder.embedding.weight  \\\n",
       "count               25.000000                 25.000000   \n",
       "mean                 0.917969                  0.661364   \n",
       "std                  0.029646                  0.078769   \n",
       "min                  0.854980                  0.526456   \n",
       "25%                  0.891602                  0.608132   \n",
       "50%                  0.929199                  0.655540   \n",
       "75%                  0.937012                  0.702770   \n",
       "max                  0.961914                  0.815341   \n",
       "\n",
       "       decoder.attention.method.mlp.weight  decoder.attention.method.mlp.bias  \\\n",
       "count                            25.000000                          25.000000   \n",
       "mean                              0.942557                           0.845234   \n",
       "std                               0.053289                           0.042907   \n",
       "min                               0.830433                           0.755859   \n",
       "25%                               0.918846                           0.822266   \n",
       "50%                               0.969986                           0.851562   \n",
       "75%                               0.983482                           0.880859   \n",
       "max                               0.991564                           0.902344   \n",
       "\n",
       "       decoder.attention.method.out.weight  decoder.out.weight  \\\n",
       "count                            25.000000           25.000000   \n",
       "mean                              0.636315            0.887791   \n",
       "std                               0.132852            0.033851   \n",
       "min                               0.386719            0.832564   \n",
       "25%                               0.590539            0.863814   \n",
       "50%                               0.649133            0.881570   \n",
       "75%                               0.744301            0.911932   \n",
       "max                               0.822266            0.956143   \n",
       "\n",
       "       decoder.out.bias  decoder.ffocus_merge.weight  \\\n",
       "count         25.000000                    25.000000   \n",
       "mean           0.549091                     0.945640   \n",
       "std            0.124427                     0.019945   \n",
       "min            0.363636                     0.900955   \n",
       "25%            0.454545                     0.935379   \n",
       "50%            0.545455                     0.947441   \n",
       "75%            0.636364                     0.963771   \n",
       "max            0.818182                     0.971615   \n",
       "\n",
       "       decoder.ffocus_merge.bias  \n",
       "count                  25.000000  \n",
       "mean                    0.860391  \n",
       "std                     0.036527  \n",
       "min                     0.787109  \n",
       "25%                     0.833984  \n",
       "50%                     0.869141  \n",
       "75%                     0.880859  \n",
       "max                     0.923828  "
      ]
     },
     "execution_count": 1009,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis_LSTM.dist.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 845,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "hPsrxPowXApN"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidrau/miniconda3/lib/python3.6/site-packages/matplotlib/pyplot.py:523: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "baseline_lstm.apply_heatmap()\n",
    "guided_lstm.apply_heatmap()\n",
    "baseline_gru.apply_heatmap()\n",
    "guided_gru.apply_heatmap()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "Untitled3.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
