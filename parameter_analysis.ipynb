{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 951,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 351
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 784,
     "status": "error",
     "timestamp": 1528712348250,
     "user": {
      "displayName": "David Rau",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "113694495446967174103"
     },
     "user_tz": -120
    },
    "id": "KLblPRiyWw77",
    "outputId": "41bc2efc-f235-471a-ed98-cc210816aff6"
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch import nn\n",
    "from seq2seq.util.checkpoint import Checkpoint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from scipy.stats import norm\n",
    "import matplotlib.mlab as mlab\n",
    "import scipy\n",
    "from mpl_toolkits.axes_grid1 import AxesGrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1012,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(object):\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        params = {}\n",
    "        for name, param in self.model.named_parameters():\n",
    "            param = param.data.numpy()\n",
    "            params[name]=pd.DataFrame(param)\n",
    "        self.params = params\n",
    "        \n",
    "    def get_param_names(self):\n",
    "        return [name for name, _ in self.model.named_parameters()]\n",
    "\n",
    "    def get_modules(self):\n",
    "        return [mod for mod in self.model.modules()]\n",
    "\n",
    "    def get_param_by_name(self, name):\n",
    "        return pd.DataFrame(self.params[name])\n",
    "\n",
    "    def heatmap(self):\n",
    "        return {k: sns.heatmap(v) for k, v in self.params.items()}\n",
    "\n",
    "    def apply_mean(self):\n",
    "        return {k: np.ravel(v).mean() if v.shape != (1,1) else np.NaN for k, v in self.params.items()}\n",
    "       \n",
    "    def apply_std(self):\n",
    "        return {k: np.ravel(v).std() if v.shape != (1,1) else np.NaN for k, v in self.params.items()}\n",
    "    \n",
    "    def apply_min(self):\n",
    "        return {k: np.ravel(v).min() for k, v in self.params.items()}\n",
    "    \n",
    "    def apply_max(self):\n",
    "        return {k: np.ravel(v).max() for k, v in self.params.items()}\n",
    "        \n",
    "    def apply_norm(self):\n",
    "        return {k: np.linalg.norm(np.ravel(v)) if v.shape != (1,1) else np.NaN for k, v in self.params.items()}\n",
    "            \n",
    "    def param_to_dist(self,name):\n",
    "        data = self.params[name]\n",
    "        data = np.ravel(data)\n",
    "#         # best fit of data\n",
    "#         (mu, sigma) = norm.fit(data)\n",
    "\n",
    "#         # the histogram of the data\n",
    "#         n, bins, patches = plt.hist(data, 20, normed=1)\n",
    "\n",
    "#         # add a 'best fit' line\n",
    "#         y = mlab.normpdf( bins, mu, sigma)\n",
    "#         l = plt.plot(bins, y, 'r--', linewidth=2)\n",
    "#        return scipy.stats.norm(mu, sigma)\n",
    "        hist, _ = np.histogram(data, bins=50, range=[-1, 1], density=True)\n",
    "        return hist\n",
    "        \n",
    "\n",
    "            \n",
    "class Models(object):\n",
    "    def mean_of(self, data):\n",
    "        one_key = list(data.keys())[0]\n",
    "        return {param: np.mean([data[name][param] for name in data.keys()]) for param in data[one_key].keys()}\n",
    "    \n",
    "    def load_models(self):\n",
    "        models = {}\n",
    "        files = os.listdir(self.model_path)\n",
    "        for file in files: \n",
    "            if not file.startswith('.'):\n",
    "                print('loading: ', self.model_path + '/' + file)\n",
    "                checkpoint = Checkpoint.load(self.model_path + '/' + file)\n",
    "                seq2seq = checkpoint.model\n",
    "                models[file] = Model(seq2seq)\n",
    "        return models\n",
    "    \n",
    "    def __init__(self, model_path,title):\n",
    "        \n",
    "        self.image_folder = 'images/'\n",
    "        self.title = title\n",
    "        self.model_path = model_path\n",
    "        \n",
    "        self.models = self.load_models()\n",
    "\n",
    "        ## calculate mean, std, norm\n",
    "        self.means = {name: model.apply_mean() for name,model in self.models.items()}\n",
    "        self.stds = {name : model.apply_std() for name,model in self.models.items()}\n",
    "        self.norms = {name: model.apply_norm() for name, model in self.models.items()}\n",
    "        self.mins = {name: model.apply_min() for name, model in self.models.items()}\n",
    "        self.maxs = {name: model.apply_max() for name, model in self.models.items()}\n",
    "        \n",
    "        ## caluclate mean of means, stds, norms\n",
    "        self.mean_of_means = self.mean_of(self.means)\n",
    "        self.mean_of_stds = self.mean_of(self.stds)\n",
    "        self.mean_of_norms = self.mean_of(self.norms) \n",
    "        self.maxs = self.mean_of(self.maxs) \n",
    "        self.mins = self.mean_of(self.mins) \n",
    "        \n",
    "        # fill data into df \n",
    "        df = pd.DataFrame.from_dict(self.mean_of_means,  orient='index')\n",
    "        df = df.rename(columns={0: 'mean of means'})\n",
    "        df['mean of stds'] = self.mean_of_stds.values()\n",
    "        df['mean of norms'] = self.mean_of_norms.values()\n",
    "        df['mean of maxs'] = self.maxs.values()\n",
    "        df['mean of mins'] = self.mins.values()\n",
    "        self.df = df        \n",
    "        \n",
    "    \n",
    "    def apply_heatmap(self):\n",
    "        for model_name, model in self.models.items():\n",
    "            for param_name in self.models[model_name].params.keys():\n",
    "                plt.figure()\n",
    "                sns.heatmap(model.params[param_name])\n",
    "                plt.title(self.title + ' (' + model_name + ') - \\n heatmap of param: ' + param_name)\n",
    "                plt.savefig('images/' + self.title + '_' + model_name + '_' + param_name + '.png', dpi=300)\n",
    "                plt.show()\n",
    "                \n",
    "    def apply_heatmap_by_name(self,param_name):\n",
    "        for model_name, model in self.models.items():\n",
    "            plt.figure()\n",
    "            sns.heatmap(model.params[param_name])\n",
    "            plt.title(self.title + ' (' + model_name + ') - \\n heatmap of param: ' + param_name)\n",
    "            plt.savefig(image_folder + self.title + '_' + model_name + '_' + param_name + '.png', dpi=300)\n",
    "            plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1013,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "G02XzQKSWtz9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading:  ../machine-zoo/guided/gru/1\n",
      "loading:  ../machine-zoo/guided/gru/2\n",
      "loading:  ../machine-zoo/guided/gru/3\n",
      "loading:  ../machine-zoo/guided/gru/4\n",
      "loading:  ../machine-zoo/guided/gru/5\n",
      "loading:  ../machine-zoo/baseline/gru/1\n",
      "loading:  ../machine-zoo/baseline/gru/2\n",
      "loading:  ../machine-zoo/baseline/gru/3\n",
      "loading:  ../machine-zoo/baseline/gru/4\n",
      "loading:  ../machine-zoo/baseline/gru/5\n",
      "loading:  ../machine-zoo/guided/lstm/1\n",
      "loading:  ../machine-zoo/guided/lstm/2\n",
      "loading:  ../machine-zoo/guided/lstm/3\n",
      "loading:  ../machine-zoo/guided/lstm/4\n",
      "loading:  ../machine-zoo/guided/lstm/5\n",
      "loading:  ../machine-zoo/baseline/lstm/1\n",
      "loading:  ../machine-zoo/baseline/lstm/2\n",
      "loading:  ../machine-zoo/baseline/lstm/3\n",
      "loading:  ../machine-zoo/baseline/lstm/4\n",
      "loading:  ../machine-zoo/baseline/lstm/5\n"
     ]
    }
   ],
   "source": [
    "guided_gru = Models('../machine-zoo/guided/gru', 'Guided_GRU')\n",
    "baseline_gru = Models('../machine-zoo/baseline/gru', 'Baseline_GRU')\n",
    "\n",
    "guided_lstm = Models('../machine-zoo/guided/lstm', 'Guided_LSTM')\n",
    "baseline_lstm = Models('../machine-zoo/baseline/lstm', 'Baseline_LSTM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sizes of layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1014,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19, 16) encoder.embedding.weight\n",
      "(2048, 16) encoder.rnn.weight_ih_l0\n",
      "(2048, 512) encoder.rnn.weight_hh_l0\n",
      "(2048, 1) encoder.rnn.bias_ih_l0\n",
      "(2048, 1) encoder.rnn.bias_hh_l0\n",
      "(2048, 512) decoder.rnn.weight_ih_l0\n",
      "(2048, 512) decoder.rnn.weight_hh_l0\n",
      "(2048, 1) decoder.rnn.bias_ih_l0\n",
      "(2048, 1) decoder.rnn.bias_hh_l0\n",
      "(11, 512) decoder.embedding.weight\n",
      "(512, 1024) decoder.attention.method.mlp.weight\n",
      "(512, 1) decoder.attention.method.mlp.bias\n",
      "(1, 512) decoder.attention.method.out.weight\n",
      "(1, 1) decoder.attention.method.out.bias\n",
      "(11, 512) decoder.out.weight\n",
      "(11, 1) decoder.out.bias\n",
      "(512, 1024) decoder.ffocus_merge.weight\n",
      "(512, 1) decoder.ffocus_merge.bias\n"
     ]
    }
   ],
   "source": [
    "for name, params in guided_lstm.models['1'].params.items():\n",
    "    print(params.shape, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Analysis\n",
    "\n",
    "Guided GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1015,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean of means</th>\n",
       "      <th>mean of stds</th>\n",
       "      <th>mean of norms</th>\n",
       "      <th>mean of maxs</th>\n",
       "      <th>mean of mins</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>encoder.embedding.weight</th>\n",
       "      <td>-0.000959</td>\n",
       "      <td>0.139349</td>\n",
       "      <td>2.429867</td>\n",
       "      <td>0.376077</td>\n",
       "      <td>-0.403524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>encoder.rnn.weight_ih_l0</th>\n",
       "      <td>-0.000206</td>\n",
       "      <td>0.080538</td>\n",
       "      <td>12.626729</td>\n",
       "      <td>0.542031</td>\n",
       "      <td>-0.511061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>encoder.rnn.weight_hh_l0</th>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.065287</td>\n",
       "      <td>57.897675</td>\n",
       "      <td>0.412640</td>\n",
       "      <td>-0.394051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>encoder.rnn.bias_ih_l0</th>\n",
       "      <td>-0.012083</td>\n",
       "      <td>0.072939</td>\n",
       "      <td>2.898563</td>\n",
       "      <td>0.176322</td>\n",
       "      <td>-0.312060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>encoder.rnn.bias_hh_l0</th>\n",
       "      <td>-0.013354</td>\n",
       "      <td>0.070808</td>\n",
       "      <td>2.824670</td>\n",
       "      <td>0.194362</td>\n",
       "      <td>-0.297983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder.rnn.weight_ih_l0</th>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.065539</td>\n",
       "      <td>58.121387</td>\n",
       "      <td>0.742477</td>\n",
       "      <td>-0.713911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder.rnn.weight_hh_l0</th>\n",
       "      <td>-0.000056</td>\n",
       "      <td>0.058843</td>\n",
       "      <td>52.185558</td>\n",
       "      <td>0.291974</td>\n",
       "      <td>-0.281988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder.rnn.bias_ih_l0</th>\n",
       "      <td>-0.025098</td>\n",
       "      <td>0.059747</td>\n",
       "      <td>2.540183</td>\n",
       "      <td>0.144791</td>\n",
       "      <td>-0.195006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder.rnn.bias_hh_l0</th>\n",
       "      <td>-0.025394</td>\n",
       "      <td>0.059537</td>\n",
       "      <td>2.536941</td>\n",
       "      <td>0.131834</td>\n",
       "      <td>-0.197489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder.embedding.weight</th>\n",
       "      <td>0.000316</td>\n",
       "      <td>0.147676</td>\n",
       "      <td>11.082689</td>\n",
       "      <td>0.395972</td>\n",
       "      <td>-0.391510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder.attention.method.mlp.weight</th>\n",
       "      <td>0.000206</td>\n",
       "      <td>0.067487</td>\n",
       "      <td>48.866028</td>\n",
       "      <td>0.675517</td>\n",
       "      <td>-0.649629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder.attention.method.mlp.bias</th>\n",
       "      <td>0.001523</td>\n",
       "      <td>0.057483</td>\n",
       "      <td>1.303248</td>\n",
       "      <td>0.321878</td>\n",
       "      <td>-0.160765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder.attention.method.out.weight</th>\n",
       "      <td>-0.051289</td>\n",
       "      <td>0.161760</td>\n",
       "      <td>3.844874</td>\n",
       "      <td>0.547918</td>\n",
       "      <td>-1.133493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder.attention.method.out.bias</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3.116120</td>\n",
       "      <td>-3.116120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder.out.weight</th>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.091697</td>\n",
       "      <td>6.883183</td>\n",
       "      <td>0.323680</td>\n",
       "      <td>-0.304038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder.out.bias</th>\n",
       "      <td>-0.008529</td>\n",
       "      <td>0.057211</td>\n",
       "      <td>0.195871</td>\n",
       "      <td>0.076822</td>\n",
       "      <td>-0.117338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder.ffocus_merge.weight</th>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.068721</td>\n",
       "      <td>49.759529</td>\n",
       "      <td>0.605410</td>\n",
       "      <td>-0.602240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder.ffocus_merge.bias</th>\n",
       "      <td>-0.011141</td>\n",
       "      <td>0.061930</td>\n",
       "      <td>1.425724</td>\n",
       "      <td>0.241186</td>\n",
       "      <td>-0.136802</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     mean of means  mean of stds  \\\n",
       "encoder.embedding.weight                 -0.000959      0.139349   \n",
       "encoder.rnn.weight_ih_l0                 -0.000206      0.080538   \n",
       "encoder.rnn.weight_hh_l0                  0.000058      0.065287   \n",
       "encoder.rnn.bias_ih_l0                   -0.012083      0.072939   \n",
       "encoder.rnn.bias_hh_l0                   -0.013354      0.070808   \n",
       "decoder.rnn.weight_ih_l0                  0.000041      0.065539   \n",
       "decoder.rnn.weight_hh_l0                 -0.000056      0.058843   \n",
       "decoder.rnn.bias_ih_l0                   -0.025098      0.059747   \n",
       "decoder.rnn.bias_hh_l0                   -0.025394      0.059537   \n",
       "decoder.embedding.weight                  0.000316      0.147676   \n",
       "decoder.attention.method.mlp.weight       0.000206      0.067487   \n",
       "decoder.attention.method.mlp.bias         0.001523      0.057483   \n",
       "decoder.attention.method.out.weight      -0.051289      0.161760   \n",
       "decoder.attention.method.out.bias              NaN           NaN   \n",
       "decoder.out.weight                        0.000153      0.091697   \n",
       "decoder.out.bias                         -0.008529      0.057211   \n",
       "decoder.ffocus_merge.weight               0.000194      0.068721   \n",
       "decoder.ffocus_merge.bias                -0.011141      0.061930   \n",
       "\n",
       "                                     mean of norms  mean of maxs  mean of mins  \n",
       "encoder.embedding.weight                  2.429867      0.376077     -0.403524  \n",
       "encoder.rnn.weight_ih_l0                 12.626729      0.542031     -0.511061  \n",
       "encoder.rnn.weight_hh_l0                 57.897675      0.412640     -0.394051  \n",
       "encoder.rnn.bias_ih_l0                    2.898563      0.176322     -0.312060  \n",
       "encoder.rnn.bias_hh_l0                    2.824670      0.194362     -0.297983  \n",
       "decoder.rnn.weight_ih_l0                 58.121387      0.742477     -0.713911  \n",
       "decoder.rnn.weight_hh_l0                 52.185558      0.291974     -0.281988  \n",
       "decoder.rnn.bias_ih_l0                    2.540183      0.144791     -0.195006  \n",
       "decoder.rnn.bias_hh_l0                    2.536941      0.131834     -0.197489  \n",
       "decoder.embedding.weight                 11.082689      0.395972     -0.391510  \n",
       "decoder.attention.method.mlp.weight      48.866028      0.675517     -0.649629  \n",
       "decoder.attention.method.mlp.bias         1.303248      0.321878     -0.160765  \n",
       "decoder.attention.method.out.weight       3.844874      0.547918     -1.133493  \n",
       "decoder.attention.method.out.bias              NaN     -3.116120     -3.116120  \n",
       "decoder.out.weight                        6.883183      0.323680     -0.304038  \n",
       "decoder.out.bias                          0.195871      0.076822     -0.117338  \n",
       "decoder.ffocus_merge.weight              49.759529      0.605410     -0.602240  \n",
       "decoder.ffocus_merge.bias                 1.425724      0.241186     -0.136802  "
      ]
     },
     "execution_count": 1015,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "guided_gru.df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1016,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean of means</th>\n",
       "      <th>mean of stds</th>\n",
       "      <th>mean of norms</th>\n",
       "      <th>mean of maxs</th>\n",
       "      <th>mean of mins</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>encoder.embedding.weight</th>\n",
       "      <td>-1.759272e-03</td>\n",
       "      <td>0.146639</td>\n",
       "      <td>2.557299</td>\n",
       "      <td>0.466294</td>\n",
       "      <td>-0.440219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>encoder.rnn.weight_ih_l0</th>\n",
       "      <td>1.795653e-03</td>\n",
       "      <td>0.132039</td>\n",
       "      <td>20.707676</td>\n",
       "      <td>0.657196</td>\n",
       "      <td>-0.636781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>encoder.rnn.weight_hh_l0</th>\n",
       "      <td>2.041644e-04</td>\n",
       "      <td>0.088030</td>\n",
       "      <td>78.066849</td>\n",
       "      <td>0.566109</td>\n",
       "      <td>-0.596124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>encoder.rnn.bias_ih_l0</th>\n",
       "      <td>-1.620729e-02</td>\n",
       "      <td>0.092863</td>\n",
       "      <td>3.695691</td>\n",
       "      <td>0.276811</td>\n",
       "      <td>-0.357539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>encoder.rnn.bias_hh_l0</th>\n",
       "      <td>-1.591059e-02</td>\n",
       "      <td>0.092919</td>\n",
       "      <td>3.696127</td>\n",
       "      <td>0.273887</td>\n",
       "      <td>-0.335439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder.rnn.weight_ih_l0</th>\n",
       "      <td>-1.277724e-04</td>\n",
       "      <td>0.068788</td>\n",
       "      <td>61.002495</td>\n",
       "      <td>0.457143</td>\n",
       "      <td>-0.430959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder.rnn.weight_hh_l0</th>\n",
       "      <td>-1.709472e-04</td>\n",
       "      <td>0.075933</td>\n",
       "      <td>67.339149</td>\n",
       "      <td>0.425063</td>\n",
       "      <td>-0.432390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder.rnn.bias_ih_l0</th>\n",
       "      <td>-2.985862e-02</td>\n",
       "      <td>0.075753</td>\n",
       "      <td>3.191333</td>\n",
       "      <td>0.192314</td>\n",
       "      <td>-0.249801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder.rnn.bias_hh_l0</th>\n",
       "      <td>-2.878932e-02</td>\n",
       "      <td>0.075507</td>\n",
       "      <td>3.167907</td>\n",
       "      <td>0.207104</td>\n",
       "      <td>-0.249486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder.embedding.weight</th>\n",
       "      <td>-6.870941e-05</td>\n",
       "      <td>0.084614</td>\n",
       "      <td>6.350204</td>\n",
       "      <td>0.323575</td>\n",
       "      <td>-0.334121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder.attention.method.mlp.weight</th>\n",
       "      <td>-4.490892e-05</td>\n",
       "      <td>0.072736</td>\n",
       "      <td>52.666878</td>\n",
       "      <td>0.343112</td>\n",
       "      <td>-0.345298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder.attention.method.mlp.bias</th>\n",
       "      <td>-2.278755e-04</td>\n",
       "      <td>0.067650</td>\n",
       "      <td>1.544677</td>\n",
       "      <td>0.177775</td>\n",
       "      <td>-0.187792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder.attention.method.out.weight</th>\n",
       "      <td>-2.773907e-02</td>\n",
       "      <td>0.078564</td>\n",
       "      <td>1.891106</td>\n",
       "      <td>0.192097</td>\n",
       "      <td>-0.258599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder.attention.method.out.bias</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.011534</td>\n",
       "      <td>-0.011534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder.out.weight</th>\n",
       "      <td>-2.991874e-07</td>\n",
       "      <td>0.093911</td>\n",
       "      <td>7.047983</td>\n",
       "      <td>0.374719</td>\n",
       "      <td>-0.368637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder.out.bias</th>\n",
       "      <td>-3.062585e-02</td>\n",
       "      <td>0.070635</td>\n",
       "      <td>0.255743</td>\n",
       "      <td>0.059661</td>\n",
       "      <td>-0.163663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder.ffocus_merge.weight</th>\n",
       "      <td>4.127148e-04</td>\n",
       "      <td>0.065934</td>\n",
       "      <td>47.742027</td>\n",
       "      <td>0.357640</td>\n",
       "      <td>-0.349222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder.ffocus_merge.bias</th>\n",
       "      <td>-4.718875e-02</td>\n",
       "      <td>0.062091</td>\n",
       "      <td>1.765792</td>\n",
       "      <td>0.153604</td>\n",
       "      <td>-0.198715</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     mean of means  mean of stds  \\\n",
       "encoder.embedding.weight             -1.759272e-03      0.146639   \n",
       "encoder.rnn.weight_ih_l0              1.795653e-03      0.132039   \n",
       "encoder.rnn.weight_hh_l0              2.041644e-04      0.088030   \n",
       "encoder.rnn.bias_ih_l0               -1.620729e-02      0.092863   \n",
       "encoder.rnn.bias_hh_l0               -1.591059e-02      0.092919   \n",
       "decoder.rnn.weight_ih_l0             -1.277724e-04      0.068788   \n",
       "decoder.rnn.weight_hh_l0             -1.709472e-04      0.075933   \n",
       "decoder.rnn.bias_ih_l0               -2.985862e-02      0.075753   \n",
       "decoder.rnn.bias_hh_l0               -2.878932e-02      0.075507   \n",
       "decoder.embedding.weight             -6.870941e-05      0.084614   \n",
       "decoder.attention.method.mlp.weight  -4.490892e-05      0.072736   \n",
       "decoder.attention.method.mlp.bias    -2.278755e-04      0.067650   \n",
       "decoder.attention.method.out.weight  -2.773907e-02      0.078564   \n",
       "decoder.attention.method.out.bias              NaN           NaN   \n",
       "decoder.out.weight                   -2.991874e-07      0.093911   \n",
       "decoder.out.bias                     -3.062585e-02      0.070635   \n",
       "decoder.ffocus_merge.weight           4.127148e-04      0.065934   \n",
       "decoder.ffocus_merge.bias            -4.718875e-02      0.062091   \n",
       "\n",
       "                                     mean of norms  mean of maxs  mean of mins  \n",
       "encoder.embedding.weight                  2.557299      0.466294     -0.440219  \n",
       "encoder.rnn.weight_ih_l0                 20.707676      0.657196     -0.636781  \n",
       "encoder.rnn.weight_hh_l0                 78.066849      0.566109     -0.596124  \n",
       "encoder.rnn.bias_ih_l0                    3.695691      0.276811     -0.357539  \n",
       "encoder.rnn.bias_hh_l0                    3.696127      0.273887     -0.335439  \n",
       "decoder.rnn.weight_ih_l0                 61.002495      0.457143     -0.430959  \n",
       "decoder.rnn.weight_hh_l0                 67.339149      0.425063     -0.432390  \n",
       "decoder.rnn.bias_ih_l0                    3.191333      0.192314     -0.249801  \n",
       "decoder.rnn.bias_hh_l0                    3.167907      0.207104     -0.249486  \n",
       "decoder.embedding.weight                  6.350204      0.323575     -0.334121  \n",
       "decoder.attention.method.mlp.weight      52.666878      0.343112     -0.345298  \n",
       "decoder.attention.method.mlp.bias         1.544677      0.177775     -0.187792  \n",
       "decoder.attention.method.out.weight       1.891106      0.192097     -0.258599  \n",
       "decoder.attention.method.out.bias              NaN     -0.011534     -0.011534  \n",
       "decoder.out.weight                        7.047983      0.374719     -0.368637  \n",
       "decoder.out.bias                          0.255743      0.059661     -0.163663  \n",
       "decoder.ffocus_merge.weight              47.742027      0.357640     -0.349222  \n",
       "decoder.ffocus_merge.bias                 1.765792      0.153604     -0.198715  "
      ]
     },
     "execution_count": 1016,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_gru.df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guided LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1017,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean of means</th>\n",
       "      <th>mean of stds</th>\n",
       "      <th>mean of norms</th>\n",
       "      <th>mean of maxs</th>\n",
       "      <th>mean of mins</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>encoder.embedding.weight</th>\n",
       "      <td>0.002058</td>\n",
       "      <td>0.179018</td>\n",
       "      <td>3.123551</td>\n",
       "      <td>0.543385</td>\n",
       "      <td>-0.524266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>encoder.rnn.weight_ih_l0</th>\n",
       "      <td>0.000245</td>\n",
       "      <td>0.113211</td>\n",
       "      <td>20.516216</td>\n",
       "      <td>0.710162</td>\n",
       "      <td>-0.710747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>encoder.rnn.weight_hh_l0</th>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.071164</td>\n",
       "      <td>72.872803</td>\n",
       "      <td>0.551239</td>\n",
       "      <td>-0.668254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>encoder.rnn.bias_ih_l0</th>\n",
       "      <td>-0.010346</td>\n",
       "      <td>0.082105</td>\n",
       "      <td>3.746127</td>\n",
       "      <td>0.408405</td>\n",
       "      <td>-0.251434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>encoder.rnn.bias_hh_l0</th>\n",
       "      <td>-0.010515</td>\n",
       "      <td>0.081048</td>\n",
       "      <td>3.700511</td>\n",
       "      <td>0.403438</td>\n",
       "      <td>-0.238568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder.rnn.weight_ih_l0</th>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.080769</td>\n",
       "      <td>82.708237</td>\n",
       "      <td>0.941351</td>\n",
       "      <td>-0.865073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder.rnn.weight_hh_l0</th>\n",
       "      <td>-0.000130</td>\n",
       "      <td>0.073191</td>\n",
       "      <td>74.948914</td>\n",
       "      <td>0.402468</td>\n",
       "      <td>-0.391413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder.rnn.bias_ih_l0</th>\n",
       "      <td>-0.024615</td>\n",
       "      <td>0.059836</td>\n",
       "      <td>2.930603</td>\n",
       "      <td>0.152430</td>\n",
       "      <td>-0.214242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder.rnn.bias_hh_l0</th>\n",
       "      <td>-0.024132</td>\n",
       "      <td>0.060696</td>\n",
       "      <td>2.957357</td>\n",
       "      <td>0.167402</td>\n",
       "      <td>-0.216230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder.embedding.weight</th>\n",
       "      <td>0.000231</td>\n",
       "      <td>0.179740</td>\n",
       "      <td>13.489433</td>\n",
       "      <td>0.491869</td>\n",
       "      <td>-0.492699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder.attention.method.mlp.weight</th>\n",
       "      <td>-0.000051</td>\n",
       "      <td>0.072047</td>\n",
       "      <td>52.168163</td>\n",
       "      <td>0.675322</td>\n",
       "      <td>-0.655570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder.attention.method.mlp.bias</th>\n",
       "      <td>-0.004275</td>\n",
       "      <td>0.059068</td>\n",
       "      <td>1.344930</td>\n",
       "      <td>0.149346</td>\n",
       "      <td>-0.203927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder.attention.method.out.weight</th>\n",
       "      <td>-0.021032</td>\n",
       "      <td>0.150352</td>\n",
       "      <td>3.439049</td>\n",
       "      <td>0.644234</td>\n",
       "      <td>-0.763243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder.attention.method.out.bias</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.256781</td>\n",
       "      <td>-2.256781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder.out.weight</th>\n",
       "      <td>-0.000893</td>\n",
       "      <td>0.140305</td>\n",
       "      <td>10.529896</td>\n",
       "      <td>0.636434</td>\n",
       "      <td>-0.688260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder.out.bias</th>\n",
       "      <td>-0.019884</td>\n",
       "      <td>0.064462</td>\n",
       "      <td>0.225579</td>\n",
       "      <td>0.073007</td>\n",
       "      <td>-0.135263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder.ffocus_merge.weight</th>\n",
       "      <td>0.000581</td>\n",
       "      <td>0.097283</td>\n",
       "      <td>70.442200</td>\n",
       "      <td>0.940061</td>\n",
       "      <td>-1.018749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder.ffocus_merge.bias</th>\n",
       "      <td>0.001793</td>\n",
       "      <td>0.091905</td>\n",
       "      <td>2.081349</td>\n",
       "      <td>0.518395</td>\n",
       "      <td>-0.174709</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     mean of means  mean of stds  \\\n",
       "encoder.embedding.weight                  0.002058      0.179018   \n",
       "encoder.rnn.weight_ih_l0                  0.000245      0.113211   \n",
       "encoder.rnn.weight_hh_l0                  0.000026      0.071164   \n",
       "encoder.rnn.bias_ih_l0                   -0.010346      0.082105   \n",
       "encoder.rnn.bias_hh_l0                   -0.010515      0.081048   \n",
       "decoder.rnn.weight_ih_l0                  0.000095      0.080769   \n",
       "decoder.rnn.weight_hh_l0                 -0.000130      0.073191   \n",
       "decoder.rnn.bias_ih_l0                   -0.024615      0.059836   \n",
       "decoder.rnn.bias_hh_l0                   -0.024132      0.060696   \n",
       "decoder.embedding.weight                  0.000231      0.179740   \n",
       "decoder.attention.method.mlp.weight      -0.000051      0.072047   \n",
       "decoder.attention.method.mlp.bias        -0.004275      0.059068   \n",
       "decoder.attention.method.out.weight      -0.021032      0.150352   \n",
       "decoder.attention.method.out.bias              NaN           NaN   \n",
       "decoder.out.weight                       -0.000893      0.140305   \n",
       "decoder.out.bias                         -0.019884      0.064462   \n",
       "decoder.ffocus_merge.weight               0.000581      0.097283   \n",
       "decoder.ffocus_merge.bias                 0.001793      0.091905   \n",
       "\n",
       "                                     mean of norms  mean of maxs  mean of mins  \n",
       "encoder.embedding.weight                  3.123551      0.543385     -0.524266  \n",
       "encoder.rnn.weight_ih_l0                 20.516216      0.710162     -0.710747  \n",
       "encoder.rnn.weight_hh_l0                 72.872803      0.551239     -0.668254  \n",
       "encoder.rnn.bias_ih_l0                    3.746127      0.408405     -0.251434  \n",
       "encoder.rnn.bias_hh_l0                    3.700511      0.403438     -0.238568  \n",
       "decoder.rnn.weight_ih_l0                 82.708237      0.941351     -0.865073  \n",
       "decoder.rnn.weight_hh_l0                 74.948914      0.402468     -0.391413  \n",
       "decoder.rnn.bias_ih_l0                    2.930603      0.152430     -0.214242  \n",
       "decoder.rnn.bias_hh_l0                    2.957357      0.167402     -0.216230  \n",
       "decoder.embedding.weight                 13.489433      0.491869     -0.492699  \n",
       "decoder.attention.method.mlp.weight      52.168163      0.675322     -0.655570  \n",
       "decoder.attention.method.mlp.bias         1.344930      0.149346     -0.203927  \n",
       "decoder.attention.method.out.weight       3.439049      0.644234     -0.763243  \n",
       "decoder.attention.method.out.bias              NaN     -2.256781     -2.256781  \n",
       "decoder.out.weight                       10.529896      0.636434     -0.688260  \n",
       "decoder.out.bias                          0.225579      0.073007     -0.135263  \n",
       "decoder.ffocus_merge.weight              70.442200      0.940061     -1.018749  \n",
       "decoder.ffocus_merge.bias                 2.081349      0.518395     -0.174709  "
      ]
     },
     "execution_count": 1017,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "guided_lstm.df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1018,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean of means</th>\n",
       "      <th>mean of stds</th>\n",
       "      <th>mean of norms</th>\n",
       "      <th>mean of maxs</th>\n",
       "      <th>mean of mins</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>encoder.embedding.weight</th>\n",
       "      <td>-0.001442</td>\n",
       "      <td>0.162086</td>\n",
       "      <td>2.826329</td>\n",
       "      <td>0.492238</td>\n",
       "      <td>-0.502056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>encoder.rnn.weight_ih_l0</th>\n",
       "      <td>0.000913</td>\n",
       "      <td>0.146842</td>\n",
       "      <td>26.588650</td>\n",
       "      <td>0.684907</td>\n",
       "      <td>-0.707094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>encoder.rnn.weight_hh_l0</th>\n",
       "      <td>-0.000176</td>\n",
       "      <td>0.089515</td>\n",
       "      <td>91.664444</td>\n",
       "      <td>0.570511</td>\n",
       "      <td>-0.610069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>encoder.rnn.bias_ih_l0</th>\n",
       "      <td>-0.037526</td>\n",
       "      <td>0.090355</td>\n",
       "      <td>4.483636</td>\n",
       "      <td>0.339953</td>\n",
       "      <td>-0.328324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>encoder.rnn.bias_hh_l0</th>\n",
       "      <td>-0.038465</td>\n",
       "      <td>0.090417</td>\n",
       "      <td>4.501397</td>\n",
       "      <td>0.307354</td>\n",
       "      <td>-0.318395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder.rnn.weight_ih_l0</th>\n",
       "      <td>-0.000139</td>\n",
       "      <td>0.080955</td>\n",
       "      <td>82.899498</td>\n",
       "      <td>0.517021</td>\n",
       "      <td>-0.515518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder.rnn.weight_hh_l0</th>\n",
       "      <td>-0.000294</td>\n",
       "      <td>0.084335</td>\n",
       "      <td>86.370056</td>\n",
       "      <td>0.489893</td>\n",
       "      <td>-0.495761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder.rnn.bias_ih_l0</th>\n",
       "      <td>-0.035166</td>\n",
       "      <td>0.065420</td>\n",
       "      <td>3.369680</td>\n",
       "      <td>0.178394</td>\n",
       "      <td>-0.243665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder.rnn.bias_hh_l0</th>\n",
       "      <td>-0.033474</td>\n",
       "      <td>0.065755</td>\n",
       "      <td>3.347765</td>\n",
       "      <td>0.171613</td>\n",
       "      <td>-0.239341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder.embedding.weight</th>\n",
       "      <td>-0.000122</td>\n",
       "      <td>0.132717</td>\n",
       "      <td>9.960362</td>\n",
       "      <td>0.474859</td>\n",
       "      <td>-0.472432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder.attention.method.mlp.weight</th>\n",
       "      <td>0.000151</td>\n",
       "      <td>0.076478</td>\n",
       "      <td>55.376179</td>\n",
       "      <td>0.431372</td>\n",
       "      <td>-0.409194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder.attention.method.mlp.bias</th>\n",
       "      <td>-0.001529</td>\n",
       "      <td>0.076091</td>\n",
       "      <td>1.727324</td>\n",
       "      <td>0.204895</td>\n",
       "      <td>-0.233515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder.attention.method.out.weight</th>\n",
       "      <td>-0.016361</td>\n",
       "      <td>0.074538</td>\n",
       "      <td>1.732655</td>\n",
       "      <td>0.212136</td>\n",
       "      <td>-0.234652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder.attention.method.out.bias</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.013143</td>\n",
       "      <td>-0.013143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder.out.weight</th>\n",
       "      <td>-0.000683</td>\n",
       "      <td>0.132103</td>\n",
       "      <td>9.916939</td>\n",
       "      <td>0.657928</td>\n",
       "      <td>-0.652494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder.out.bias</th>\n",
       "      <td>-0.052845</td>\n",
       "      <td>0.090152</td>\n",
       "      <td>0.349216</td>\n",
       "      <td>0.055984</td>\n",
       "      <td>-0.216444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder.ffocus_merge.weight</th>\n",
       "      <td>-0.000076</td>\n",
       "      <td>0.081449</td>\n",
       "      <td>58.976460</td>\n",
       "      <td>0.427680</td>\n",
       "      <td>-0.436542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder.ffocus_merge.bias</th>\n",
       "      <td>-0.026911</td>\n",
       "      <td>0.073290</td>\n",
       "      <td>1.773785</td>\n",
       "      <td>0.202077</td>\n",
       "      <td>-0.213816</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     mean of means  mean of stds  \\\n",
       "encoder.embedding.weight                 -0.001442      0.162086   \n",
       "encoder.rnn.weight_ih_l0                  0.000913      0.146842   \n",
       "encoder.rnn.weight_hh_l0                 -0.000176      0.089515   \n",
       "encoder.rnn.bias_ih_l0                   -0.037526      0.090355   \n",
       "encoder.rnn.bias_hh_l0                   -0.038465      0.090417   \n",
       "decoder.rnn.weight_ih_l0                 -0.000139      0.080955   \n",
       "decoder.rnn.weight_hh_l0                 -0.000294      0.084335   \n",
       "decoder.rnn.bias_ih_l0                   -0.035166      0.065420   \n",
       "decoder.rnn.bias_hh_l0                   -0.033474      0.065755   \n",
       "decoder.embedding.weight                 -0.000122      0.132717   \n",
       "decoder.attention.method.mlp.weight       0.000151      0.076478   \n",
       "decoder.attention.method.mlp.bias        -0.001529      0.076091   \n",
       "decoder.attention.method.out.weight      -0.016361      0.074538   \n",
       "decoder.attention.method.out.bias              NaN           NaN   \n",
       "decoder.out.weight                       -0.000683      0.132103   \n",
       "decoder.out.bias                         -0.052845      0.090152   \n",
       "decoder.ffocus_merge.weight              -0.000076      0.081449   \n",
       "decoder.ffocus_merge.bias                -0.026911      0.073290   \n",
       "\n",
       "                                     mean of norms  mean of maxs  mean of mins  \n",
       "encoder.embedding.weight                  2.826329      0.492238     -0.502056  \n",
       "encoder.rnn.weight_ih_l0                 26.588650      0.684907     -0.707094  \n",
       "encoder.rnn.weight_hh_l0                 91.664444      0.570511     -0.610069  \n",
       "encoder.rnn.bias_ih_l0                    4.483636      0.339953     -0.328324  \n",
       "encoder.rnn.bias_hh_l0                    4.501397      0.307354     -0.318395  \n",
       "decoder.rnn.weight_ih_l0                 82.899498      0.517021     -0.515518  \n",
       "decoder.rnn.weight_hh_l0                 86.370056      0.489893     -0.495761  \n",
       "decoder.rnn.bias_ih_l0                    3.369680      0.178394     -0.243665  \n",
       "decoder.rnn.bias_hh_l0                    3.347765      0.171613     -0.239341  \n",
       "decoder.embedding.weight                  9.960362      0.474859     -0.472432  \n",
       "decoder.attention.method.mlp.weight      55.376179      0.431372     -0.409194  \n",
       "decoder.attention.method.mlp.bias         1.727324      0.204895     -0.233515  \n",
       "decoder.attention.method.out.weight       1.732655      0.212136     -0.234652  \n",
       "decoder.attention.method.out.bias              NaN     -0.013143     -0.013143  \n",
       "decoder.out.weight                        9.916939      0.657928     -0.652494  \n",
       "decoder.out.bias                          0.349216      0.055984     -0.216444  \n",
       "decoder.ffocus_merge.weight              58.976460      0.427680     -0.436542  \n",
       "decoder.ffocus_merge.bias                 1.773785      0.202077     -0.213816  "
      ]
     },
     "execution_count": 1018,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_lstm.df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of Distribution\n",
    "\n",
    "GRU Guided vs. Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1042,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Analysis(object):\n",
    "    \n",
    "    def return_intersection(self, hist_1, hist_2):\n",
    "        minima = np.minimum(hist_1, hist_2)\n",
    "        intersection = np.true_divide(np.sum(minima), np.sum(hist_2))\n",
    "        return intersection\n",
    "\n",
    "    def KL(self,dist_1, dist_2):\n",
    "        x = np.linspace(-1, 1, 100)\n",
    "        return scipy.stats.entropy(dist_1.pdf(x),dist_2.pdf(x))  \n",
    "    \n",
    "    def compare_distributions(self):\n",
    "        dist = {}\n",
    "        for model_name_A in self.models_A.keys():\n",
    "            for model_name_B in self.models_B.keys():\n",
    "                per_model = {}\n",
    "                for param in self.models_A[list(self.models_A.keys())[0]].params.keys():\n",
    "                    if not self.models_A[model_name_A].params[param].shape == (1,1):\n",
    "                        dist_1 = self.models_A[model_name_A].param_to_dist(param)\n",
    "                        dist_2 = self.models_B[model_name_B].param_to_dist(param)\n",
    "                        per_model[param] = self.return_intersection(dist_1, dist_2)\n",
    "                key = model_name_A + '_' + model_name_B\n",
    "                dist[key] = per_model\n",
    "        return pd.DataFrame.from_dict(dist, orient='index')\n",
    "    \n",
    "    def compare_dist_within(self, models):\n",
    "        dist = {}\n",
    "        for param in models[list(models.keys())[0]].params.keys():\n",
    "            within_model = {}\n",
    "            for model_name_A in models.keys():\n",
    "                for model_name_B in models.keys():\n",
    "                    if (model_name_A != model_name_B) and (not models[model_name_A].params[param].shape == (1,1)):\n",
    "                        dist_1 = models[model_name_A].param_to_dist(param)\n",
    "                        dist_2 = models[model_name_B].param_to_dist(param)\n",
    "                        key = model_name_A + '_' + model_name_B\n",
    "                        within_model[key] = self.return_intersection(dist_1, dist_2)\n",
    "                dist[param] = within_model\n",
    "        return pd.DataFrame.from_dict(dist, orient='index')\n",
    "    \n",
    "    def __init__(self, models_A, models_B):\n",
    "        self.models_A = models_A.models\n",
    "        self.models_B = models_B.models\n",
    "        self.dist = self.compare_distributions()\n",
    "        self.dist_within_A = self.compare_dist_within(self.models_A)\n",
    "        self.dist_within_B = self.compare_dist_within(self.models_B)\n",
    "        \n",
    "    def compare_dist_by_name(self,param):\n",
    "        for model_name in self.models_A.keys():\n",
    "            assert(self.models_A[model_name].params[param].shape != (1,1))\n",
    "            dist_1 = self.models_A[model_name].param_to_dist(param)\n",
    "            dist_2 = self.models_B[model_name].param_to_dist(param)\n",
    "            print(self.return_intersection(dist_1, dist_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1043,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "analysis_GRU = Analysis(baseline_gru, guided_gru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1044,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encoder.embedding.weight</th>\n",
       "      <th>encoder.rnn.weight_ih_l0</th>\n",
       "      <th>encoder.rnn.weight_hh_l0</th>\n",
       "      <th>encoder.rnn.bias_ih_l0</th>\n",
       "      <th>encoder.rnn.bias_hh_l0</th>\n",
       "      <th>decoder.rnn.weight_ih_l0</th>\n",
       "      <th>decoder.rnn.weight_hh_l0</th>\n",
       "      <th>decoder.rnn.bias_ih_l0</th>\n",
       "      <th>decoder.rnn.bias_hh_l0</th>\n",
       "      <th>decoder.embedding.weight</th>\n",
       "      <th>decoder.attention.method.mlp.weight</th>\n",
       "      <th>decoder.attention.method.mlp.bias</th>\n",
       "      <th>decoder.attention.method.out.weight</th>\n",
       "      <th>decoder.out.weight</th>\n",
       "      <th>decoder.out.bias</th>\n",
       "      <th>decoder.ffocus_merge.weight</th>\n",
       "      <th>decoder.ffocus_merge.bias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.868816</td>\n",
       "      <td>0.744264</td>\n",
       "      <td>0.864755</td>\n",
       "      <td>0.875599</td>\n",
       "      <td>0.872526</td>\n",
       "      <td>0.933552</td>\n",
       "      <td>0.892613</td>\n",
       "      <td>0.893203</td>\n",
       "      <td>0.893776</td>\n",
       "      <td>0.566214</td>\n",
       "      <td>0.941055</td>\n",
       "      <td>0.874766</td>\n",
       "      <td>0.565773</td>\n",
       "      <td>0.918111</td>\n",
       "      <td>0.592727</td>\n",
       "      <td>0.956731</td>\n",
       "      <td>0.786563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.016620</td>\n",
       "      <td>0.019523</td>\n",
       "      <td>0.019201</td>\n",
       "      <td>0.031462</td>\n",
       "      <td>0.034271</td>\n",
       "      <td>0.012509</td>\n",
       "      <td>0.015916</td>\n",
       "      <td>0.016076</td>\n",
       "      <td>0.022599</td>\n",
       "      <td>0.032272</td>\n",
       "      <td>0.017775</td>\n",
       "      <td>0.024357</td>\n",
       "      <td>0.116134</td>\n",
       "      <td>0.015593</td>\n",
       "      <td>0.141616</td>\n",
       "      <td>0.011778</td>\n",
       "      <td>0.034763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.845395</td>\n",
       "      <td>0.703044</td>\n",
       "      <td>0.826725</td>\n",
       "      <td>0.827474</td>\n",
       "      <td>0.830078</td>\n",
       "      <td>0.912841</td>\n",
       "      <td>0.861463</td>\n",
       "      <td>0.867839</td>\n",
       "      <td>0.848307</td>\n",
       "      <td>0.517578</td>\n",
       "      <td>0.910160</td>\n",
       "      <td>0.824219</td>\n",
       "      <td>0.365234</td>\n",
       "      <td>0.891335</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.936085</td>\n",
       "      <td>0.730469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.858553</td>\n",
       "      <td>0.732178</td>\n",
       "      <td>0.854861</td>\n",
       "      <td>0.847005</td>\n",
       "      <td>0.847656</td>\n",
       "      <td>0.923400</td>\n",
       "      <td>0.880046</td>\n",
       "      <td>0.882812</td>\n",
       "      <td>0.878255</td>\n",
       "      <td>0.540661</td>\n",
       "      <td>0.933981</td>\n",
       "      <td>0.859375</td>\n",
       "      <td>0.474609</td>\n",
       "      <td>0.908913</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.947453</td>\n",
       "      <td>0.765625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.865132</td>\n",
       "      <td>0.744303</td>\n",
       "      <td>0.865724</td>\n",
       "      <td>0.881510</td>\n",
       "      <td>0.863281</td>\n",
       "      <td>0.931273</td>\n",
       "      <td>0.892869</td>\n",
       "      <td>0.891927</td>\n",
       "      <td>0.893229</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.938148</td>\n",
       "      <td>0.876953</td>\n",
       "      <td>0.582031</td>\n",
       "      <td>0.919212</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.955082</td>\n",
       "      <td>0.777344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.881579</td>\n",
       "      <td>0.757406</td>\n",
       "      <td>0.875916</td>\n",
       "      <td>0.890625</td>\n",
       "      <td>0.882161</td>\n",
       "      <td>0.945811</td>\n",
       "      <td>0.905159</td>\n",
       "      <td>0.902995</td>\n",
       "      <td>0.910156</td>\n",
       "      <td>0.586470</td>\n",
       "      <td>0.948311</td>\n",
       "      <td>0.888672</td>\n",
       "      <td>0.651218</td>\n",
       "      <td>0.930220</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.967932</td>\n",
       "      <td>0.818359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.904605</td>\n",
       "      <td>0.776123</td>\n",
       "      <td>0.903155</td>\n",
       "      <td>0.927734</td>\n",
       "      <td>0.940104</td>\n",
       "      <td>0.953189</td>\n",
       "      <td>0.923272</td>\n",
       "      <td>0.929036</td>\n",
       "      <td>0.934245</td>\n",
       "      <td>0.640270</td>\n",
       "      <td>0.974909</td>\n",
       "      <td>0.919922</td>\n",
       "      <td>0.757813</td>\n",
       "      <td>0.945845</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.973284</td>\n",
       "      <td>0.861328</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       encoder.embedding.weight  encoder.rnn.weight_ih_l0  \\\n",
       "count                 25.000000                 25.000000   \n",
       "mean                   0.868816                  0.744264   \n",
       "std                    0.016620                  0.019523   \n",
       "min                    0.845395                  0.703044   \n",
       "25%                    0.858553                  0.732178   \n",
       "50%                    0.865132                  0.744303   \n",
       "75%                    0.881579                  0.757406   \n",
       "max                    0.904605                  0.776123   \n",
       "\n",
       "       encoder.rnn.weight_hh_l0  encoder.rnn.bias_ih_l0  \\\n",
       "count                 25.000000               25.000000   \n",
       "mean                   0.864755                0.875599   \n",
       "std                    0.019201                0.031462   \n",
       "min                    0.826725                0.827474   \n",
       "25%                    0.854861                0.847005   \n",
       "50%                    0.865724                0.881510   \n",
       "75%                    0.875916                0.890625   \n",
       "max                    0.903155                0.927734   \n",
       "\n",
       "       encoder.rnn.bias_hh_l0  decoder.rnn.weight_ih_l0  \\\n",
       "count               25.000000                 25.000000   \n",
       "mean                 0.872526                  0.933552   \n",
       "std                  0.034271                  0.012509   \n",
       "min                  0.830078                  0.912841   \n",
       "25%                  0.847656                  0.923400   \n",
       "50%                  0.863281                  0.931273   \n",
       "75%                  0.882161                  0.945811   \n",
       "max                  0.940104                  0.953189   \n",
       "\n",
       "       decoder.rnn.weight_hh_l0  decoder.rnn.bias_ih_l0  \\\n",
       "count                 25.000000               25.000000   \n",
       "mean                   0.892613                0.893203   \n",
       "std                    0.015916                0.016076   \n",
       "min                    0.861463                0.867839   \n",
       "25%                    0.880046                0.882812   \n",
       "50%                    0.892869                0.891927   \n",
       "75%                    0.905159                0.902995   \n",
       "max                    0.923272                0.929036   \n",
       "\n",
       "       decoder.rnn.bias_hh_l0  decoder.embedding.weight  \\\n",
       "count               25.000000                 25.000000   \n",
       "mean                 0.893776                  0.566214   \n",
       "std                  0.022599                  0.032272   \n",
       "min                  0.848307                  0.517578   \n",
       "25%                  0.878255                  0.540661   \n",
       "50%                  0.893229                  0.562500   \n",
       "75%                  0.910156                  0.586470   \n",
       "max                  0.934245                  0.640270   \n",
       "\n",
       "       decoder.attention.method.mlp.weight  decoder.attention.method.mlp.bias  \\\n",
       "count                            25.000000                          25.000000   \n",
       "mean                              0.941055                           0.874766   \n",
       "std                               0.017775                           0.024357   \n",
       "min                               0.910160                           0.824219   \n",
       "25%                               0.933981                           0.859375   \n",
       "50%                               0.938148                           0.876953   \n",
       "75%                               0.948311                           0.888672   \n",
       "max                               0.974909                           0.919922   \n",
       "\n",
       "       decoder.attention.method.out.weight  decoder.out.weight  \\\n",
       "count                            25.000000           25.000000   \n",
       "mean                              0.565773            0.918111   \n",
       "std                               0.116134            0.015593   \n",
       "min                               0.365234            0.891335   \n",
       "25%                               0.474609            0.908913   \n",
       "50%                               0.582031            0.919212   \n",
       "75%                               0.651218            0.930220   \n",
       "max                               0.757813            0.945845   \n",
       "\n",
       "       decoder.out.bias  decoder.ffocus_merge.weight  \\\n",
       "count         25.000000                    25.000000   \n",
       "mean           0.592727                     0.956731   \n",
       "std            0.141616                     0.011778   \n",
       "min            0.363636                     0.936085   \n",
       "25%            0.454545                     0.947453   \n",
       "50%            0.545455                     0.955082   \n",
       "75%            0.727273                     0.967932   \n",
       "max            0.818182                     0.973284   \n",
       "\n",
       "       decoder.ffocus_merge.bias  \n",
       "count                  25.000000  \n",
       "mean                    0.786563  \n",
       "std                     0.034763  \n",
       "min                     0.730469  \n",
       "25%                     0.765625  \n",
       "50%                     0.777344  \n",
       "75%                     0.818359  \n",
       "max                     0.861328  "
      ]
     },
     "execution_count": 1044,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis_GRU.dist.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GRU distribution within Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1045,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>decoder.attention.method.mlp.bias</th>\n",
       "      <th>decoder.attention.method.mlp.weight</th>\n",
       "      <th>decoder.attention.method.out.weight</th>\n",
       "      <th>decoder.embedding.weight</th>\n",
       "      <th>decoder.ffocus_merge.bias</th>\n",
       "      <th>decoder.ffocus_merge.weight</th>\n",
       "      <th>decoder.out.bias</th>\n",
       "      <th>decoder.out.weight</th>\n",
       "      <th>decoder.rnn.bias_hh_l0</th>\n",
       "      <th>decoder.rnn.bias_ih_l0</th>\n",
       "      <th>decoder.rnn.weight_hh_l0</th>\n",
       "      <th>decoder.rnn.weight_ih_l0</th>\n",
       "      <th>encoder.embedding.weight</th>\n",
       "      <th>encoder.rnn.bias_hh_l0</th>\n",
       "      <th>encoder.rnn.bias_ih_l0</th>\n",
       "      <th>encoder.rnn.weight_hh_l0</th>\n",
       "      <th>encoder.rnn.weight_ih_l0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.904102</td>\n",
       "      <td>0.976657</td>\n",
       "      <td>0.793750</td>\n",
       "      <td>0.937891</td>\n",
       "      <td>0.918555</td>\n",
       "      <td>0.978475</td>\n",
       "      <td>0.563636</td>\n",
       "      <td>0.961310</td>\n",
       "      <td>0.949349</td>\n",
       "      <td>0.955924</td>\n",
       "      <td>0.987535</td>\n",
       "      <td>0.982306</td>\n",
       "      <td>0.877632</td>\n",
       "      <td>0.934635</td>\n",
       "      <td>0.933138</td>\n",
       "      <td>0.977396</td>\n",
       "      <td>0.970605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.029293</td>\n",
       "      <td>0.016048</td>\n",
       "      <td>0.051785</td>\n",
       "      <td>0.032583</td>\n",
       "      <td>0.031710</td>\n",
       "      <td>0.012559</td>\n",
       "      <td>0.143285</td>\n",
       "      <td>0.011808</td>\n",
       "      <td>0.011599</td>\n",
       "      <td>0.010687</td>\n",
       "      <td>0.006555</td>\n",
       "      <td>0.009659</td>\n",
       "      <td>0.030740</td>\n",
       "      <td>0.020181</td>\n",
       "      <td>0.015986</td>\n",
       "      <td>0.012826</td>\n",
       "      <td>0.010356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.853516</td>\n",
       "      <td>0.944164</td>\n",
       "      <td>0.722656</td>\n",
       "      <td>0.879261</td>\n",
       "      <td>0.859375</td>\n",
       "      <td>0.963852</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.941584</td>\n",
       "      <td>0.930990</td>\n",
       "      <td>0.936849</td>\n",
       "      <td>0.975995</td>\n",
       "      <td>0.968484</td>\n",
       "      <td>0.832237</td>\n",
       "      <td>0.901042</td>\n",
       "      <td>0.910807</td>\n",
       "      <td>0.951706</td>\n",
       "      <td>0.958618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.880859</td>\n",
       "      <td>0.968166</td>\n",
       "      <td>0.761719</td>\n",
       "      <td>0.912642</td>\n",
       "      <td>0.902344</td>\n",
       "      <td>0.966871</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.952770</td>\n",
       "      <td>0.941406</td>\n",
       "      <td>0.944010</td>\n",
       "      <td>0.982014</td>\n",
       "      <td>0.976097</td>\n",
       "      <td>0.845395</td>\n",
       "      <td>0.927734</td>\n",
       "      <td>0.920573</td>\n",
       "      <td>0.969648</td>\n",
       "      <td>0.959595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.905273</td>\n",
       "      <td>0.974147</td>\n",
       "      <td>0.784180</td>\n",
       "      <td>0.945401</td>\n",
       "      <td>0.924805</td>\n",
       "      <td>0.975695</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.962979</td>\n",
       "      <td>0.951172</td>\n",
       "      <td>0.958984</td>\n",
       "      <td>0.988106</td>\n",
       "      <td>0.979717</td>\n",
       "      <td>0.878289</td>\n",
       "      <td>0.935872</td>\n",
       "      <td>0.933594</td>\n",
       "      <td>0.980388</td>\n",
       "      <td>0.970703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.925781</td>\n",
       "      <td>0.996176</td>\n",
       "      <td>0.804687</td>\n",
       "      <td>0.966264</td>\n",
       "      <td>0.943359</td>\n",
       "      <td>0.990767</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.971236</td>\n",
       "      <td>0.952474</td>\n",
       "      <td>0.962891</td>\n",
       "      <td>0.993974</td>\n",
       "      <td>0.991597</td>\n",
       "      <td>0.907895</td>\n",
       "      <td>0.947266</td>\n",
       "      <td>0.941406</td>\n",
       "      <td>0.988794</td>\n",
       "      <td>0.979533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.943359</td>\n",
       "      <td>0.997530</td>\n",
       "      <td>0.912109</td>\n",
       "      <td>0.973544</td>\n",
       "      <td>0.966797</td>\n",
       "      <td>0.996452</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.979581</td>\n",
       "      <td>0.970703</td>\n",
       "      <td>0.972005</td>\n",
       "      <td>0.995593</td>\n",
       "      <td>0.995433</td>\n",
       "      <td>0.917763</td>\n",
       "      <td>0.962891</td>\n",
       "      <td>0.961589</td>\n",
       "      <td>0.993234</td>\n",
       "      <td>0.989502</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       decoder.attention.method.mlp.bias  decoder.attention.method.mlp.weight  \\\n",
       "count                          20.000000                            20.000000   \n",
       "mean                            0.904102                             0.976657   \n",
       "std                             0.029293                             0.016048   \n",
       "min                             0.853516                             0.944164   \n",
       "25%                             0.880859                             0.968166   \n",
       "50%                             0.905273                             0.974147   \n",
       "75%                             0.925781                             0.996176   \n",
       "max                             0.943359                             0.997530   \n",
       "\n",
       "       decoder.attention.method.out.weight  decoder.embedding.weight  \\\n",
       "count                            20.000000                 20.000000   \n",
       "mean                              0.793750                  0.937891   \n",
       "std                               0.051785                  0.032583   \n",
       "min                               0.722656                  0.879261   \n",
       "25%                               0.761719                  0.912642   \n",
       "50%                               0.784180                  0.945401   \n",
       "75%                               0.804687                  0.966264   \n",
       "max                               0.912109                  0.973544   \n",
       "\n",
       "       decoder.ffocus_merge.bias  decoder.ffocus_merge.weight  \\\n",
       "count                  20.000000                    20.000000   \n",
       "mean                    0.918555                     0.978475   \n",
       "std                     0.031710                     0.012559   \n",
       "min                     0.859375                     0.963852   \n",
       "25%                     0.902344                     0.966871   \n",
       "50%                     0.924805                     0.975695   \n",
       "75%                     0.943359                     0.990767   \n",
       "max                     0.966797                     0.996452   \n",
       "\n",
       "       decoder.out.bias  decoder.out.weight  decoder.rnn.bias_hh_l0  \\\n",
       "count         20.000000           20.000000               20.000000   \n",
       "mean           0.563636            0.961310                0.949349   \n",
       "std            0.143285            0.011808                0.011599   \n",
       "min            0.454545            0.941584                0.930990   \n",
       "25%            0.454545            0.952770                0.941406   \n",
       "50%            0.454545            0.962979                0.951172   \n",
       "75%            0.727273            0.971236                0.952474   \n",
       "max            0.818182            0.979581                0.970703   \n",
       "\n",
       "       decoder.rnn.bias_ih_l0  decoder.rnn.weight_hh_l0  \\\n",
       "count               20.000000                 20.000000   \n",
       "mean                 0.955924                  0.987535   \n",
       "std                  0.010687                  0.006555   \n",
       "min                  0.936849                  0.975995   \n",
       "25%                  0.944010                  0.982014   \n",
       "50%                  0.958984                  0.988106   \n",
       "75%                  0.962891                  0.993974   \n",
       "max                  0.972005                  0.995593   \n",
       "\n",
       "       decoder.rnn.weight_ih_l0  encoder.embedding.weight  \\\n",
       "count                 20.000000                 20.000000   \n",
       "mean                   0.982306                  0.877632   \n",
       "std                    0.009659                  0.030740   \n",
       "min                    0.968484                  0.832237   \n",
       "25%                    0.976097                  0.845395   \n",
       "50%                    0.979717                  0.878289   \n",
       "75%                    0.991597                  0.907895   \n",
       "max                    0.995433                  0.917763   \n",
       "\n",
       "       encoder.rnn.bias_hh_l0  encoder.rnn.bias_ih_l0  \\\n",
       "count               20.000000               20.000000   \n",
       "mean                 0.934635                0.933138   \n",
       "std                  0.020181                0.015986   \n",
       "min                  0.901042                0.910807   \n",
       "25%                  0.927734                0.920573   \n",
       "50%                  0.935872                0.933594   \n",
       "75%                  0.947266                0.941406   \n",
       "max                  0.962891                0.961589   \n",
       "\n",
       "       encoder.rnn.weight_hh_l0  encoder.rnn.weight_ih_l0  \n",
       "count                 20.000000                 20.000000  \n",
       "mean                   0.977396                  0.970605  \n",
       "std                    0.012826                  0.010356  \n",
       "min                    0.951706                  0.958618  \n",
       "25%                    0.969648                  0.959595  \n",
       "50%                    0.980388                  0.970703  \n",
       "75%                    0.988794                  0.979533  \n",
       "max                    0.993234                  0.989502  "
      ]
     },
     "execution_count": 1045,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis_GRU.dist_within_A.T.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GRU distribution within Guided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1046,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>decoder.attention.method.mlp.bias</th>\n",
       "      <th>decoder.attention.method.mlp.weight</th>\n",
       "      <th>decoder.attention.method.out.weight</th>\n",
       "      <th>decoder.embedding.weight</th>\n",
       "      <th>decoder.ffocus_merge.bias</th>\n",
       "      <th>decoder.ffocus_merge.weight</th>\n",
       "      <th>decoder.out.bias</th>\n",
       "      <th>decoder.out.weight</th>\n",
       "      <th>decoder.rnn.bias_hh_l0</th>\n",
       "      <th>decoder.rnn.bias_ih_l0</th>\n",
       "      <th>decoder.rnn.weight_hh_l0</th>\n",
       "      <th>decoder.rnn.weight_ih_l0</th>\n",
       "      <th>encoder.embedding.weight</th>\n",
       "      <th>encoder.rnn.bias_hh_l0</th>\n",
       "      <th>encoder.rnn.bias_ih_l0</th>\n",
       "      <th>encoder.rnn.weight_hh_l0</th>\n",
       "      <th>encoder.rnn.weight_ih_l0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.949219</td>\n",
       "      <td>0.990875</td>\n",
       "      <td>0.824148</td>\n",
       "      <td>0.950284</td>\n",
       "      <td>0.931641</td>\n",
       "      <td>0.991665</td>\n",
       "      <td>0.609091</td>\n",
       "      <td>0.975568</td>\n",
       "      <td>0.973763</td>\n",
       "      <td>0.962630</td>\n",
       "      <td>0.981162</td>\n",
       "      <td>0.993493</td>\n",
       "      <td>0.876974</td>\n",
       "      <td>0.963932</td>\n",
       "      <td>0.959180</td>\n",
       "      <td>0.987489</td>\n",
       "      <td>0.978223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.008549</td>\n",
       "      <td>0.003208</td>\n",
       "      <td>0.049207</td>\n",
       "      <td>0.014041</td>\n",
       "      <td>0.017051</td>\n",
       "      <td>0.003653</td>\n",
       "      <td>0.177214</td>\n",
       "      <td>0.005024</td>\n",
       "      <td>0.008066</td>\n",
       "      <td>0.007808</td>\n",
       "      <td>0.008861</td>\n",
       "      <td>0.002736</td>\n",
       "      <td>0.017679</td>\n",
       "      <td>0.010592</td>\n",
       "      <td>0.010068</td>\n",
       "      <td>0.008517</td>\n",
       "      <td>0.007818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.935547</td>\n",
       "      <td>0.985191</td>\n",
       "      <td>0.738281</td>\n",
       "      <td>0.928622</td>\n",
       "      <td>0.898437</td>\n",
       "      <td>0.983929</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.970170</td>\n",
       "      <td>0.957031</td>\n",
       "      <td>0.947266</td>\n",
       "      <td>0.962195</td>\n",
       "      <td>0.988605</td>\n",
       "      <td>0.848684</td>\n",
       "      <td>0.943359</td>\n",
       "      <td>0.943359</td>\n",
       "      <td>0.971859</td>\n",
       "      <td>0.963379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.943359</td>\n",
       "      <td>0.989058</td>\n",
       "      <td>0.791016</td>\n",
       "      <td>0.939986</td>\n",
       "      <td>0.921875</td>\n",
       "      <td>0.989885</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.970526</td>\n",
       "      <td>0.971354</td>\n",
       "      <td>0.957031</td>\n",
       "      <td>0.974440</td>\n",
       "      <td>0.991144</td>\n",
       "      <td>0.865132</td>\n",
       "      <td>0.961589</td>\n",
       "      <td>0.953776</td>\n",
       "      <td>0.980502</td>\n",
       "      <td>0.972005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.949219</td>\n",
       "      <td>0.991209</td>\n",
       "      <td>0.841223</td>\n",
       "      <td>0.951083</td>\n",
       "      <td>0.933594</td>\n",
       "      <td>0.992360</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.974964</td>\n",
       "      <td>0.973307</td>\n",
       "      <td>0.963216</td>\n",
       "      <td>0.985835</td>\n",
       "      <td>0.993839</td>\n",
       "      <td>0.878289</td>\n",
       "      <td>0.966146</td>\n",
       "      <td>0.957682</td>\n",
       "      <td>0.990720</td>\n",
       "      <td>0.980815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.953125</td>\n",
       "      <td>0.993398</td>\n",
       "      <td>0.855469</td>\n",
       "      <td>0.960405</td>\n",
       "      <td>0.943359</td>\n",
       "      <td>0.994270</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.979403</td>\n",
       "      <td>0.979818</td>\n",
       "      <td>0.970703</td>\n",
       "      <td>0.987755</td>\n",
       "      <td>0.995491</td>\n",
       "      <td>0.888158</td>\n",
       "      <td>0.970703</td>\n",
       "      <td>0.968099</td>\n",
       "      <td>0.994704</td>\n",
       "      <td>0.984701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.966797</td>\n",
       "      <td>0.995244</td>\n",
       "      <td>0.886121</td>\n",
       "      <td>0.969638</td>\n",
       "      <td>0.957031</td>\n",
       "      <td>0.996153</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.985263</td>\n",
       "      <td>0.986328</td>\n",
       "      <td>0.972005</td>\n",
       "      <td>0.991168</td>\n",
       "      <td>0.996934</td>\n",
       "      <td>0.907895</td>\n",
       "      <td>0.977214</td>\n",
       "      <td>0.973958</td>\n",
       "      <td>0.998002</td>\n",
       "      <td>0.988078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       decoder.attention.method.mlp.bias  decoder.attention.method.mlp.weight  \\\n",
       "count                          20.000000                            20.000000   \n",
       "mean                            0.949219                             0.990875   \n",
       "std                             0.008549                             0.003208   \n",
       "min                             0.935547                             0.985191   \n",
       "25%                             0.943359                             0.989058   \n",
       "50%                             0.949219                             0.991209   \n",
       "75%                             0.953125                             0.993398   \n",
       "max                             0.966797                             0.995244   \n",
       "\n",
       "       decoder.attention.method.out.weight  decoder.embedding.weight  \\\n",
       "count                            20.000000                 20.000000   \n",
       "mean                              0.824148                  0.950284   \n",
       "std                               0.049207                  0.014041   \n",
       "min                               0.738281                  0.928622   \n",
       "25%                               0.791016                  0.939986   \n",
       "50%                               0.841223                  0.951083   \n",
       "75%                               0.855469                  0.960405   \n",
       "max                               0.886121                  0.969638   \n",
       "\n",
       "       decoder.ffocus_merge.bias  decoder.ffocus_merge.weight  \\\n",
       "count                  20.000000                    20.000000   \n",
       "mean                    0.931641                     0.991665   \n",
       "std                     0.017051                     0.003653   \n",
       "min                     0.898437                     0.983929   \n",
       "25%                     0.921875                     0.989885   \n",
       "50%                     0.933594                     0.992360   \n",
       "75%                     0.943359                     0.994270   \n",
       "max                     0.957031                     0.996153   \n",
       "\n",
       "       decoder.out.bias  decoder.out.weight  decoder.rnn.bias_hh_l0  \\\n",
       "count         20.000000           20.000000               20.000000   \n",
       "mean           0.609091            0.975568                0.973763   \n",
       "std            0.177214            0.005024                0.008066   \n",
       "min            0.363636            0.970170                0.957031   \n",
       "25%            0.454545            0.970526                0.971354   \n",
       "50%            0.545455            0.974964                0.973307   \n",
       "75%            0.818182            0.979403                0.979818   \n",
       "max            0.909091            0.985263                0.986328   \n",
       "\n",
       "       decoder.rnn.bias_ih_l0  decoder.rnn.weight_hh_l0  \\\n",
       "count               20.000000                 20.000000   \n",
       "mean                 0.962630                  0.981162   \n",
       "std                  0.007808                  0.008861   \n",
       "min                  0.947266                  0.962195   \n",
       "25%                  0.957031                  0.974440   \n",
       "50%                  0.963216                  0.985835   \n",
       "75%                  0.970703                  0.987755   \n",
       "max                  0.972005                  0.991168   \n",
       "\n",
       "       decoder.rnn.weight_ih_l0  encoder.embedding.weight  \\\n",
       "count                 20.000000                 20.000000   \n",
       "mean                   0.993493                  0.876974   \n",
       "std                    0.002736                  0.017679   \n",
       "min                    0.988605                  0.848684   \n",
       "25%                    0.991144                  0.865132   \n",
       "50%                    0.993839                  0.878289   \n",
       "75%                    0.995491                  0.888158   \n",
       "max                    0.996934                  0.907895   \n",
       "\n",
       "       encoder.rnn.bias_hh_l0  encoder.rnn.bias_ih_l0  \\\n",
       "count               20.000000               20.000000   \n",
       "mean                 0.963932                0.959180   \n",
       "std                  0.010592                0.010068   \n",
       "min                  0.943359                0.943359   \n",
       "25%                  0.961589                0.953776   \n",
       "50%                  0.966146                0.957682   \n",
       "75%                  0.970703                0.968099   \n",
       "max                  0.977214                0.973958   \n",
       "\n",
       "       encoder.rnn.weight_hh_l0  encoder.rnn.weight_ih_l0  \n",
       "count                 20.000000                 20.000000  \n",
       "mean                   0.987489                  0.978223  \n",
       "std                    0.008517                  0.007818  \n",
       "min                    0.971859                  0.963379  \n",
       "25%                    0.980502                  0.972005  \n",
       "50%                    0.990720                  0.980815  \n",
       "75%                    0.994704                  0.984701  \n",
       "max                    0.998002                  0.988078  "
      ]
     },
     "execution_count": 1046,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis_GRU.dist_within_B.T.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM Guided vs. Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1047,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "analysis_LSTM = Analysis(guided_lstm, baseline_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1048,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encoder.embedding.weight</th>\n",
       "      <th>encoder.rnn.weight_ih_l0</th>\n",
       "      <th>encoder.rnn.weight_hh_l0</th>\n",
       "      <th>encoder.rnn.bias_ih_l0</th>\n",
       "      <th>encoder.rnn.bias_hh_l0</th>\n",
       "      <th>decoder.rnn.weight_ih_l0</th>\n",
       "      <th>decoder.rnn.weight_hh_l0</th>\n",
       "      <th>decoder.rnn.bias_ih_l0</th>\n",
       "      <th>decoder.rnn.bias_hh_l0</th>\n",
       "      <th>decoder.embedding.weight</th>\n",
       "      <th>decoder.attention.method.mlp.weight</th>\n",
       "      <th>decoder.attention.method.mlp.bias</th>\n",
       "      <th>decoder.attention.method.out.weight</th>\n",
       "      <th>decoder.out.weight</th>\n",
       "      <th>decoder.out.bias</th>\n",
       "      <th>decoder.ffocus_merge.weight</th>\n",
       "      <th>decoder.ffocus_merge.bias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.844079</td>\n",
       "      <td>0.844094</td>\n",
       "      <td>0.898595</td>\n",
       "      <td>0.874434</td>\n",
       "      <td>0.868320</td>\n",
       "      <td>0.951818</td>\n",
       "      <td>0.938035</td>\n",
       "      <td>0.910605</td>\n",
       "      <td>0.917969</td>\n",
       "      <td>0.661364</td>\n",
       "      <td>0.942557</td>\n",
       "      <td>0.845234</td>\n",
       "      <td>0.636315</td>\n",
       "      <td>0.887791</td>\n",
       "      <td>0.549091</td>\n",
       "      <td>0.945640</td>\n",
       "      <td>0.860391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.028249</td>\n",
       "      <td>0.090856</td>\n",
       "      <td>0.064630</td>\n",
       "      <td>0.092074</td>\n",
       "      <td>0.096388</td>\n",
       "      <td>0.037297</td>\n",
       "      <td>0.052990</td>\n",
       "      <td>0.028361</td>\n",
       "      <td>0.029646</td>\n",
       "      <td>0.078769</td>\n",
       "      <td>0.053289</td>\n",
       "      <td>0.042907</td>\n",
       "      <td>0.132852</td>\n",
       "      <td>0.033851</td>\n",
       "      <td>0.124427</td>\n",
       "      <td>0.019945</td>\n",
       "      <td>0.036527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.782895</td>\n",
       "      <td>0.652130</td>\n",
       "      <td>0.776758</td>\n",
       "      <td>0.683105</td>\n",
       "      <td>0.677246</td>\n",
       "      <td>0.869842</td>\n",
       "      <td>0.824250</td>\n",
       "      <td>0.864746</td>\n",
       "      <td>0.854980</td>\n",
       "      <td>0.526456</td>\n",
       "      <td>0.830433</td>\n",
       "      <td>0.755859</td>\n",
       "      <td>0.386719</td>\n",
       "      <td>0.832564</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.900955</td>\n",
       "      <td>0.787109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.822368</td>\n",
       "      <td>0.768921</td>\n",
       "      <td>0.862494</td>\n",
       "      <td>0.857910</td>\n",
       "      <td>0.841797</td>\n",
       "      <td>0.935133</td>\n",
       "      <td>0.936102</td>\n",
       "      <td>0.889648</td>\n",
       "      <td>0.891602</td>\n",
       "      <td>0.608132</td>\n",
       "      <td>0.918846</td>\n",
       "      <td>0.822266</td>\n",
       "      <td>0.590539</td>\n",
       "      <td>0.863814</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.935379</td>\n",
       "      <td>0.833984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.851974</td>\n",
       "      <td>0.858276</td>\n",
       "      <td>0.906240</td>\n",
       "      <td>0.910156</td>\n",
       "      <td>0.905762</td>\n",
       "      <td>0.969708</td>\n",
       "      <td>0.953884</td>\n",
       "      <td>0.913086</td>\n",
       "      <td>0.929199</td>\n",
       "      <td>0.655540</td>\n",
       "      <td>0.969986</td>\n",
       "      <td>0.851562</td>\n",
       "      <td>0.649133</td>\n",
       "      <td>0.881570</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.947441</td>\n",
       "      <td>0.869141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.868421</td>\n",
       "      <td>0.913635</td>\n",
       "      <td>0.938403</td>\n",
       "      <td>0.935547</td>\n",
       "      <td>0.943359</td>\n",
       "      <td>0.977510</td>\n",
       "      <td>0.976146</td>\n",
       "      <td>0.927734</td>\n",
       "      <td>0.937012</td>\n",
       "      <td>0.702770</td>\n",
       "      <td>0.983482</td>\n",
       "      <td>0.880859</td>\n",
       "      <td>0.744301</td>\n",
       "      <td>0.911932</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.963771</td>\n",
       "      <td>0.880859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.878289</td>\n",
       "      <td>0.968445</td>\n",
       "      <td>0.995316</td>\n",
       "      <td>0.966309</td>\n",
       "      <td>0.965820</td>\n",
       "      <td>0.991642</td>\n",
       "      <td>0.995377</td>\n",
       "      <td>0.957520</td>\n",
       "      <td>0.961914</td>\n",
       "      <td>0.815341</td>\n",
       "      <td>0.991564</td>\n",
       "      <td>0.902344</td>\n",
       "      <td>0.822266</td>\n",
       "      <td>0.956143</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.971615</td>\n",
       "      <td>0.923828</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       encoder.embedding.weight  encoder.rnn.weight_ih_l0  \\\n",
       "count                 25.000000                 25.000000   \n",
       "mean                   0.844079                  0.844094   \n",
       "std                    0.028249                  0.090856   \n",
       "min                    0.782895                  0.652130   \n",
       "25%                    0.822368                  0.768921   \n",
       "50%                    0.851974                  0.858276   \n",
       "75%                    0.868421                  0.913635   \n",
       "max                    0.878289                  0.968445   \n",
       "\n",
       "       encoder.rnn.weight_hh_l0  encoder.rnn.bias_ih_l0  \\\n",
       "count                 25.000000               25.000000   \n",
       "mean                   0.898595                0.874434   \n",
       "std                    0.064630                0.092074   \n",
       "min                    0.776758                0.683105   \n",
       "25%                    0.862494                0.857910   \n",
       "50%                    0.906240                0.910156   \n",
       "75%                    0.938403                0.935547   \n",
       "max                    0.995316                0.966309   \n",
       "\n",
       "       encoder.rnn.bias_hh_l0  decoder.rnn.weight_ih_l0  \\\n",
       "count               25.000000                 25.000000   \n",
       "mean                 0.868320                  0.951818   \n",
       "std                  0.096388                  0.037297   \n",
       "min                  0.677246                  0.869842   \n",
       "25%                  0.841797                  0.935133   \n",
       "50%                  0.905762                  0.969708   \n",
       "75%                  0.943359                  0.977510   \n",
       "max                  0.965820                  0.991642   \n",
       "\n",
       "       decoder.rnn.weight_hh_l0  decoder.rnn.bias_ih_l0  \\\n",
       "count                 25.000000               25.000000   \n",
       "mean                   0.938035                0.910605   \n",
       "std                    0.052990                0.028361   \n",
       "min                    0.824250                0.864746   \n",
       "25%                    0.936102                0.889648   \n",
       "50%                    0.953884                0.913086   \n",
       "75%                    0.976146                0.927734   \n",
       "max                    0.995377                0.957520   \n",
       "\n",
       "       decoder.rnn.bias_hh_l0  decoder.embedding.weight  \\\n",
       "count               25.000000                 25.000000   \n",
       "mean                 0.917969                  0.661364   \n",
       "std                  0.029646                  0.078769   \n",
       "min                  0.854980                  0.526456   \n",
       "25%                  0.891602                  0.608132   \n",
       "50%                  0.929199                  0.655540   \n",
       "75%                  0.937012                  0.702770   \n",
       "max                  0.961914                  0.815341   \n",
       "\n",
       "       decoder.attention.method.mlp.weight  decoder.attention.method.mlp.bias  \\\n",
       "count                            25.000000                          25.000000   \n",
       "mean                              0.942557                           0.845234   \n",
       "std                               0.053289                           0.042907   \n",
       "min                               0.830433                           0.755859   \n",
       "25%                               0.918846                           0.822266   \n",
       "50%                               0.969986                           0.851562   \n",
       "75%                               0.983482                           0.880859   \n",
       "max                               0.991564                           0.902344   \n",
       "\n",
       "       decoder.attention.method.out.weight  decoder.out.weight  \\\n",
       "count                            25.000000           25.000000   \n",
       "mean                              0.636315            0.887791   \n",
       "std                               0.132852            0.033851   \n",
       "min                               0.386719            0.832564   \n",
       "25%                               0.590539            0.863814   \n",
       "50%                               0.649133            0.881570   \n",
       "75%                               0.744301            0.911932   \n",
       "max                               0.822266            0.956143   \n",
       "\n",
       "       decoder.out.bias  decoder.ffocus_merge.weight  \\\n",
       "count         25.000000                    25.000000   \n",
       "mean           0.549091                     0.945640   \n",
       "std            0.124427                     0.019945   \n",
       "min            0.363636                     0.900955   \n",
       "25%            0.454545                     0.935379   \n",
       "50%            0.545455                     0.947441   \n",
       "75%            0.636364                     0.963771   \n",
       "max            0.818182                     0.971615   \n",
       "\n",
       "       decoder.ffocus_merge.bias  \n",
       "count                  25.000000  \n",
       "mean                    0.860391  \n",
       "std                     0.036527  \n",
       "min                     0.787109  \n",
       "25%                     0.833984  \n",
       "50%                     0.869141  \n",
       "75%                     0.880859  \n",
       "max                     0.923828  "
      ]
     },
     "execution_count": 1048,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis_LSTM.dist.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM distribution within Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1040,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>decoder.attention.method.mlp.bias</th>\n",
       "      <th>decoder.attention.method.mlp.weight</th>\n",
       "      <th>decoder.attention.method.out.weight</th>\n",
       "      <th>decoder.embedding.weight</th>\n",
       "      <th>decoder.ffocus_merge.bias</th>\n",
       "      <th>decoder.ffocus_merge.weight</th>\n",
       "      <th>decoder.out.bias</th>\n",
       "      <th>decoder.out.weight</th>\n",
       "      <th>decoder.rnn.bias_hh_l0</th>\n",
       "      <th>decoder.rnn.bias_ih_l0</th>\n",
       "      <th>decoder.rnn.weight_hh_l0</th>\n",
       "      <th>decoder.rnn.weight_ih_l0</th>\n",
       "      <th>encoder.embedding.weight</th>\n",
       "      <th>encoder.rnn.bias_hh_l0</th>\n",
       "      <th>encoder.rnn.bias_ih_l0</th>\n",
       "      <th>encoder.rnn.weight_hh_l0</th>\n",
       "      <th>encoder.rnn.weight_ih_l0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.926172</td>\n",
       "      <td>0.982899</td>\n",
       "      <td>0.853680</td>\n",
       "      <td>0.923828</td>\n",
       "      <td>0.914062</td>\n",
       "      <td>0.979446</td>\n",
       "      <td>0.554545</td>\n",
       "      <td>0.949911</td>\n",
       "      <td>0.955957</td>\n",
       "      <td>0.953662</td>\n",
       "      <td>0.980909</td>\n",
       "      <td>0.978113</td>\n",
       "      <td>0.845066</td>\n",
       "      <td>0.944678</td>\n",
       "      <td>0.950439</td>\n",
       "      <td>0.978631</td>\n",
       "      <td>0.931378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.023976</td>\n",
       "      <td>0.008314</td>\n",
       "      <td>0.027138</td>\n",
       "      <td>0.024637</td>\n",
       "      <td>0.014561</td>\n",
       "      <td>0.010835</td>\n",
       "      <td>0.105935</td>\n",
       "      <td>0.011467</td>\n",
       "      <td>0.012536</td>\n",
       "      <td>0.015582</td>\n",
       "      <td>0.011446</td>\n",
       "      <td>0.013330</td>\n",
       "      <td>0.031059</td>\n",
       "      <td>0.011881</td>\n",
       "      <td>0.015049</td>\n",
       "      <td>0.011058</td>\n",
       "      <td>0.026959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.884766</td>\n",
       "      <td>0.965364</td>\n",
       "      <td>0.793546</td>\n",
       "      <td>0.875355</td>\n",
       "      <td>0.896484</td>\n",
       "      <td>0.957707</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.930930</td>\n",
       "      <td>0.935547</td>\n",
       "      <td>0.929688</td>\n",
       "      <td>0.959282</td>\n",
       "      <td>0.954600</td>\n",
       "      <td>0.799342</td>\n",
       "      <td>0.924316</td>\n",
       "      <td>0.915527</td>\n",
       "      <td>0.956105</td>\n",
       "      <td>0.879486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.904297</td>\n",
       "      <td>0.978104</td>\n",
       "      <td>0.848589</td>\n",
       "      <td>0.901278</td>\n",
       "      <td>0.902344</td>\n",
       "      <td>0.972893</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.940163</td>\n",
       "      <td>0.945312</td>\n",
       "      <td>0.941406</td>\n",
       "      <td>0.977062</td>\n",
       "      <td>0.964038</td>\n",
       "      <td>0.822368</td>\n",
       "      <td>0.934570</td>\n",
       "      <td>0.946289</td>\n",
       "      <td>0.970917</td>\n",
       "      <td>0.917786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.926758</td>\n",
       "      <td>0.985091</td>\n",
       "      <td>0.856036</td>\n",
       "      <td>0.929066</td>\n",
       "      <td>0.908203</td>\n",
       "      <td>0.981558</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.949396</td>\n",
       "      <td>0.956299</td>\n",
       "      <td>0.948975</td>\n",
       "      <td>0.981562</td>\n",
       "      <td>0.980787</td>\n",
       "      <td>0.847039</td>\n",
       "      <td>0.945068</td>\n",
       "      <td>0.953857</td>\n",
       "      <td>0.983753</td>\n",
       "      <td>0.938431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.941406</td>\n",
       "      <td>0.989031</td>\n",
       "      <td>0.867187</td>\n",
       "      <td>0.937855</td>\n",
       "      <td>0.929687</td>\n",
       "      <td>0.987520</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.957031</td>\n",
       "      <td>0.966309</td>\n",
       "      <td>0.967773</td>\n",
       "      <td>0.988399</td>\n",
       "      <td>0.990439</td>\n",
       "      <td>0.858553</td>\n",
       "      <td>0.951660</td>\n",
       "      <td>0.958496</td>\n",
       "      <td>0.986762</td>\n",
       "      <td>0.954315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.962891</td>\n",
       "      <td>0.992342</td>\n",
       "      <td>0.894202</td>\n",
       "      <td>0.956143</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.992867</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.967685</td>\n",
       "      <td>0.976074</td>\n",
       "      <td>0.975586</td>\n",
       "      <td>0.997905</td>\n",
       "      <td>0.995173</td>\n",
       "      <td>0.914474</td>\n",
       "      <td>0.964844</td>\n",
       "      <td>0.971680</td>\n",
       "      <td>0.992181</td>\n",
       "      <td>0.964478</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       decoder.attention.method.mlp.bias  decoder.attention.method.mlp.weight  \\\n",
       "count                          20.000000                            20.000000   \n",
       "mean                            0.926172                             0.982899   \n",
       "std                             0.023976                             0.008314   \n",
       "min                             0.884766                             0.965364   \n",
       "25%                             0.904297                             0.978104   \n",
       "50%                             0.926758                             0.985091   \n",
       "75%                             0.941406                             0.989031   \n",
       "max                             0.962891                             0.992342   \n",
       "\n",
       "       decoder.attention.method.out.weight  decoder.embedding.weight  \\\n",
       "count                            20.000000                 20.000000   \n",
       "mean                              0.853680                  0.923828   \n",
       "std                               0.027138                  0.024637   \n",
       "min                               0.793546                  0.875355   \n",
       "25%                               0.848589                  0.901278   \n",
       "50%                               0.856036                  0.929066   \n",
       "75%                               0.867187                  0.937855   \n",
       "max                               0.894202                  0.956143   \n",
       "\n",
       "       decoder.ffocus_merge.bias  decoder.ffocus_merge.weight  \\\n",
       "count                  20.000000                    20.000000   \n",
       "mean                    0.914062                     0.979446   \n",
       "std                     0.014561                     0.010835   \n",
       "min                     0.896484                     0.957707   \n",
       "25%                     0.902344                     0.972893   \n",
       "50%                     0.908203                     0.981558   \n",
       "75%                     0.929687                     0.987520   \n",
       "max                     0.937500                     0.992867   \n",
       "\n",
       "       decoder.out.bias  decoder.out.weight  decoder.rnn.bias_hh_l0  \\\n",
       "count         20.000000           20.000000               20.000000   \n",
       "mean           0.554545            0.949911                0.955957   \n",
       "std            0.105935            0.011467                0.012536   \n",
       "min            0.454545            0.930930                0.935547   \n",
       "25%            0.454545            0.940163                0.945312   \n",
       "50%            0.545455            0.949396                0.956299   \n",
       "75%            0.636364            0.957031                0.966309   \n",
       "max            0.727273            0.967685                0.976074   \n",
       "\n",
       "       decoder.rnn.bias_ih_l0  decoder.rnn.weight_hh_l0  \\\n",
       "count               20.000000                 20.000000   \n",
       "mean                 0.953662                  0.980909   \n",
       "std                  0.015582                  0.011446   \n",
       "min                  0.929688                  0.959282   \n",
       "25%                  0.941406                  0.977062   \n",
       "50%                  0.948975                  0.981562   \n",
       "75%                  0.967773                  0.988399   \n",
       "max                  0.975586                  0.997905   \n",
       "\n",
       "       decoder.rnn.weight_ih_l0  encoder.embedding.weight  \\\n",
       "count                 20.000000                 20.000000   \n",
       "mean                   0.978113                  0.845066   \n",
       "std                    0.013330                  0.031059   \n",
       "min                    0.954600                  0.799342   \n",
       "25%                    0.964038                  0.822368   \n",
       "50%                    0.980787                  0.847039   \n",
       "75%                    0.990439                  0.858553   \n",
       "max                    0.995173                  0.914474   \n",
       "\n",
       "       encoder.rnn.bias_hh_l0  encoder.rnn.bias_ih_l0  \\\n",
       "count               20.000000               20.000000   \n",
       "mean                 0.944678                0.950439   \n",
       "std                  0.011881                0.015049   \n",
       "min                  0.924316                0.915527   \n",
       "25%                  0.934570                0.946289   \n",
       "50%                  0.945068                0.953857   \n",
       "75%                  0.951660                0.958496   \n",
       "max                  0.964844                0.971680   \n",
       "\n",
       "       encoder.rnn.weight_hh_l0  encoder.rnn.weight_ih_l0  \n",
       "count                 20.000000                 20.000000  \n",
       "mean                   0.978631                  0.931378  \n",
       "std                    0.011058                  0.026959  \n",
       "min                    0.956105                  0.879486  \n",
       "25%                    0.970917                  0.917786  \n",
       "50%                    0.983753                  0.938431  \n",
       "75%                    0.986762                  0.954315  \n",
       "max                    0.992181                  0.964478  "
      ]
     },
     "execution_count": 1040,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis_LSTM.dist_within_A.T.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM distribution within Guided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1050,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>decoder.attention.method.mlp.bias</th>\n",
       "      <th>decoder.attention.method.mlp.weight</th>\n",
       "      <th>decoder.attention.method.out.weight</th>\n",
       "      <th>decoder.embedding.weight</th>\n",
       "      <th>decoder.ffocus_merge.bias</th>\n",
       "      <th>decoder.ffocus_merge.weight</th>\n",
       "      <th>decoder.out.bias</th>\n",
       "      <th>decoder.out.weight</th>\n",
       "      <th>decoder.rnn.bias_hh_l0</th>\n",
       "      <th>decoder.rnn.bias_ih_l0</th>\n",
       "      <th>decoder.rnn.weight_hh_l0</th>\n",
       "      <th>decoder.rnn.weight_ih_l0</th>\n",
       "      <th>encoder.embedding.weight</th>\n",
       "      <th>encoder.rnn.bias_hh_l0</th>\n",
       "      <th>encoder.rnn.bias_ih_l0</th>\n",
       "      <th>encoder.rnn.weight_hh_l0</th>\n",
       "      <th>encoder.rnn.weight_ih_l0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.898242</td>\n",
       "      <td>0.929037</td>\n",
       "      <td>0.766406</td>\n",
       "      <td>0.836115</td>\n",
       "      <td>0.882227</td>\n",
       "      <td>0.935238</td>\n",
       "      <td>0.527273</td>\n",
       "      <td>0.894283</td>\n",
       "      <td>0.927881</td>\n",
       "      <td>0.922803</td>\n",
       "      <td>0.931231</td>\n",
       "      <td>0.937875</td>\n",
       "      <td>0.839803</td>\n",
       "      <td>0.838428</td>\n",
       "      <td>0.851855</td>\n",
       "      <td>0.909964</td>\n",
       "      <td>0.846725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.026712</td>\n",
       "      <td>0.052292</td>\n",
       "      <td>0.099526</td>\n",
       "      <td>0.074627</td>\n",
       "      <td>0.030732</td>\n",
       "      <td>0.036078</td>\n",
       "      <td>0.130579</td>\n",
       "      <td>0.066375</td>\n",
       "      <td>0.034534</td>\n",
       "      <td>0.030875</td>\n",
       "      <td>0.051783</td>\n",
       "      <td>0.039479</td>\n",
       "      <td>0.023819</td>\n",
       "      <td>0.096397</td>\n",
       "      <td>0.096680</td>\n",
       "      <td>0.049387</td>\n",
       "      <td>0.079452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.853516</td>\n",
       "      <td>0.856874</td>\n",
       "      <td>0.591797</td>\n",
       "      <td>0.689453</td>\n",
       "      <td>0.828125</td>\n",
       "      <td>0.867384</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.785334</td>\n",
       "      <td>0.878906</td>\n",
       "      <td>0.868652</td>\n",
       "      <td>0.837410</td>\n",
       "      <td>0.868717</td>\n",
       "      <td>0.786184</td>\n",
       "      <td>0.685547</td>\n",
       "      <td>0.696289</td>\n",
       "      <td>0.804965</td>\n",
       "      <td>0.682556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.880859</td>\n",
       "      <td>0.863214</td>\n",
       "      <td>0.736328</td>\n",
       "      <td>0.763494</td>\n",
       "      <td>0.876953</td>\n",
       "      <td>0.909126</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.818892</td>\n",
       "      <td>0.891113</td>\n",
       "      <td>0.898926</td>\n",
       "      <td>0.888148</td>\n",
       "      <td>0.897515</td>\n",
       "      <td>0.828947</td>\n",
       "      <td>0.741211</td>\n",
       "      <td>0.747559</td>\n",
       "      <td>0.874923</td>\n",
       "      <td>0.788300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.890625</td>\n",
       "      <td>0.934115</td>\n",
       "      <td>0.782227</td>\n",
       "      <td>0.867898</td>\n",
       "      <td>0.886719</td>\n",
       "      <td>0.947485</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.929510</td>\n",
       "      <td>0.940186</td>\n",
       "      <td>0.918701</td>\n",
       "      <td>0.948925</td>\n",
       "      <td>0.945325</td>\n",
       "      <td>0.840461</td>\n",
       "      <td>0.881592</td>\n",
       "      <td>0.901367</td>\n",
       "      <td>0.919159</td>\n",
       "      <td>0.882492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.921875</td>\n",
       "      <td>0.991573</td>\n",
       "      <td>0.845703</td>\n",
       "      <td>0.901811</td>\n",
       "      <td>0.910156</td>\n",
       "      <td>0.958042</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.952770</td>\n",
       "      <td>0.958008</td>\n",
       "      <td>0.956055</td>\n",
       "      <td>0.981480</td>\n",
       "      <td>0.971201</td>\n",
       "      <td>0.851974</td>\n",
       "      <td>0.924805</td>\n",
       "      <td>0.931641</td>\n",
       "      <td>0.940362</td>\n",
       "      <td>0.897339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.943359</td>\n",
       "      <td>0.992342</td>\n",
       "      <td>0.882812</td>\n",
       "      <td>0.907138</td>\n",
       "      <td>0.917969</td>\n",
       "      <td>0.986622</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.961648</td>\n",
       "      <td>0.972656</td>\n",
       "      <td>0.963379</td>\n",
       "      <td>0.996182</td>\n",
       "      <td>0.991217</td>\n",
       "      <td>0.871711</td>\n",
       "      <td>0.936523</td>\n",
       "      <td>0.954102</td>\n",
       "      <td>0.973829</td>\n",
       "      <td>0.963409</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       decoder.attention.method.mlp.bias  decoder.attention.method.mlp.weight  \\\n",
       "count                          20.000000                            20.000000   \n",
       "mean                            0.898242                             0.929037   \n",
       "std                             0.026712                             0.052292   \n",
       "min                             0.853516                             0.856874   \n",
       "25%                             0.880859                             0.863214   \n",
       "50%                             0.890625                             0.934115   \n",
       "75%                             0.921875                             0.991573   \n",
       "max                             0.943359                             0.992342   \n",
       "\n",
       "       decoder.attention.method.out.weight  decoder.embedding.weight  \\\n",
       "count                            20.000000                 20.000000   \n",
       "mean                              0.766406                  0.836115   \n",
       "std                               0.099526                  0.074627   \n",
       "min                               0.591797                  0.689453   \n",
       "25%                               0.736328                  0.763494   \n",
       "50%                               0.782227                  0.867898   \n",
       "75%                               0.845703                  0.901811   \n",
       "max                               0.882812                  0.907138   \n",
       "\n",
       "       decoder.ffocus_merge.bias  decoder.ffocus_merge.weight  \\\n",
       "count                  20.000000                    20.000000   \n",
       "mean                    0.882227                     0.935238   \n",
       "std                     0.030732                     0.036078   \n",
       "min                     0.828125                     0.867384   \n",
       "25%                     0.876953                     0.909126   \n",
       "50%                     0.886719                     0.947485   \n",
       "75%                     0.910156                     0.958042   \n",
       "max                     0.917969                     0.986622   \n",
       "\n",
       "       decoder.out.bias  decoder.out.weight  decoder.rnn.bias_hh_l0  \\\n",
       "count         20.000000           20.000000               20.000000   \n",
       "mean           0.527273            0.894283                0.927881   \n",
       "std            0.130579            0.066375                0.034534   \n",
       "min            0.363636            0.785334                0.878906   \n",
       "25%            0.454545            0.818892                0.891113   \n",
       "50%            0.500000            0.929510                0.940186   \n",
       "75%            0.636364            0.952770                0.958008   \n",
       "max            0.727273            0.961648                0.972656   \n",
       "\n",
       "       decoder.rnn.bias_ih_l0  decoder.rnn.weight_hh_l0  \\\n",
       "count               20.000000                 20.000000   \n",
       "mean                 0.922803                  0.931231   \n",
       "std                  0.030875                  0.051783   \n",
       "min                  0.868652                  0.837410   \n",
       "25%                  0.898926                  0.888148   \n",
       "50%                  0.918701                  0.948925   \n",
       "75%                  0.956055                  0.981480   \n",
       "max                  0.963379                  0.996182   \n",
       "\n",
       "       decoder.rnn.weight_ih_l0  encoder.embedding.weight  \\\n",
       "count                 20.000000                 20.000000   \n",
       "mean                   0.937875                  0.839803   \n",
       "std                    0.039479                  0.023819   \n",
       "min                    0.868717                  0.786184   \n",
       "25%                    0.897515                  0.828947   \n",
       "50%                    0.945325                  0.840461   \n",
       "75%                    0.971201                  0.851974   \n",
       "max                    0.991217                  0.871711   \n",
       "\n",
       "       encoder.rnn.bias_hh_l0  encoder.rnn.bias_ih_l0  \\\n",
       "count               20.000000               20.000000   \n",
       "mean                 0.838428                0.851855   \n",
       "std                  0.096397                0.096680   \n",
       "min                  0.685547                0.696289   \n",
       "25%                  0.741211                0.747559   \n",
       "50%                  0.881592                0.901367   \n",
       "75%                  0.924805                0.931641   \n",
       "max                  0.936523                0.954102   \n",
       "\n",
       "       encoder.rnn.weight_hh_l0  encoder.rnn.weight_ih_l0  \n",
       "count                 20.000000                 20.000000  \n",
       "mean                   0.909964                  0.846725  \n",
       "std                    0.049387                  0.079452  \n",
       "min                    0.804965                  0.682556  \n",
       "25%                    0.874923                  0.788300  \n",
       "50%                    0.919159                  0.882492  \n",
       "75%                    0.940362                  0.897339  \n",
       "max                    0.973829                  0.963409  "
      ]
     },
     "execution_count": 1050,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis_LSTM.dist_within_B.T.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 845,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "hPsrxPowXApN"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidrau/miniconda3/lib/python3.6/site-packages/matplotlib/pyplot.py:523: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "baseline_lstm.apply_heatmap()\n",
    "guided_lstm.apply_heatmap()\n",
    "baseline_gru.apply_heatmap()\n",
    "guided_gru.apply_heatmap()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "Untitled3.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
